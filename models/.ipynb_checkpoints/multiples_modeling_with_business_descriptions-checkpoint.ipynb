{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fa65eb",
   "metadata": {},
   "source": [
    "### EV/sales modeling with business descriptions and NO SIC code in input database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad276f",
   "metadata": {},
   "source": [
    "In this script we are going to train different ML models with three main types of architecture: Random Forest, Gradient Boosting, and Support Vector Machine. Our dependent variable is the EV/Sales multiple, and the independent ones are the financial metrics selected from the financial features analysis + the encoded business description of the firm, accounting for a qualitative description of the business' operating activity. Each model is trained and tested 50 times with different initialization seeds and hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "524994a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f35c79",
   "metadata": {},
   "source": [
    "We are now going to define all the project-related folders and loading out Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d779607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9b86b3-9e7f-455b-88cc-4d812707f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_folder: Path = Path(\"/Users/giovanni/Documents/QVF - quantitative framework for valuation multiples computation in mergers and acquisitions/data/00_raw\")\n",
    "dataset_excel_file_name: str = (\n",
    "    \"sic_industrial_and_commercial_machinery_and_computer_equipment.xlsx\"\n",
    ")\n",
    "dataset_excel_sheet_reference: str = \"Filtered Results\"\n",
    "\n",
    "# Load Excel file\n",
    "data_frame: pd.DataFrame = pd.read_excel(\n",
    "    io=data_folder.joinpath(dataset_excel_file_name),\n",
    "    sheet_name=dataset_excel_sheet_reference,\n",
    ")\n",
    "data_frame.columns = data_frame.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d427119-e67b-4625-920e-d95c38899bf4",
   "metadata": {},
   "source": [
    "## Setting independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "082205e5-d96e-4d4b-a533-3b8c0f2a4260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.940031</td>\n",
       "      <td>-1.200982</td>\n",
       "      <td>1.386171</td>\n",
       "      <td>1.421958</td>\n",
       "      <td>1.295752</td>\n",
       "      <td>1.127542</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>1.265011</td>\n",
       "      <td>-0.948901</td>\n",
       "      <td>-0.650675</td>\n",
       "      <td>0.457350</td>\n",
       "      <td>-1.682913</td>\n",
       "      <td>0.035319</td>\n",
       "      <td>-1.430782</td>\n",
       "      <td>-1.052864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.969031</td>\n",
       "      <td>0.568739</td>\n",
       "      <td>-0.995405</td>\n",
       "      <td>-0.047311</td>\n",
       "      <td>0.065348</td>\n",
       "      <td>0.300497</td>\n",
       "      <td>-1.188035</td>\n",
       "      <td>0.392371</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>-1.473936</td>\n",
       "      <td>0.133124</td>\n",
       "      <td>-0.383836</td>\n",
       "      <td>-0.231574</td>\n",
       "      <td>-0.033198</td>\n",
       "      <td>-0.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.991280</td>\n",
       "      <td>0.521885</td>\n",
       "      <td>-0.436549</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>-0.152528</td>\n",
       "      <td>-0.051827</td>\n",
       "      <td>-0.032181</td>\n",
       "      <td>0.157405</td>\n",
       "      <td>-0.084538</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0.186401</td>\n",
       "      <td>-0.063512</td>\n",
       "      <td>0.148592</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>-0.068546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071584</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>-0.075963</td>\n",
       "      <td>0.183511</td>\n",
       "      <td>0.772674</td>\n",
       "      <td>2.509305</td>\n",
       "      <td>0.796459</td>\n",
       "      <td>-1.710631</td>\n",
       "      <td>0.078906</td>\n",
       "      <td>0.619381</td>\n",
       "      <td>-0.470390</td>\n",
       "      <td>-0.409396</td>\n",
       "      <td>-0.884893</td>\n",
       "      <td>-0.360189</td>\n",
       "      <td>0.075540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.378382</td>\n",
       "      <td>0.166162</td>\n",
       "      <td>0.388914</td>\n",
       "      <td>-1.702416</td>\n",
       "      <td>-1.438576</td>\n",
       "      <td>1.328583</td>\n",
       "      <td>-0.152559</td>\n",
       "      <td>0.229676</td>\n",
       "      <td>-0.745418</td>\n",
       "      <td>-0.293819</td>\n",
       "      <td>0.358246</td>\n",
       "      <td>-0.725692</td>\n",
       "      <td>0.428501</td>\n",
       "      <td>0.600632</td>\n",
       "      <td>-0.138775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>-0.038565</td>\n",
       "      <td>0.198642</td>\n",
       "      <td>0.312745</td>\n",
       "      <td>0.838248</td>\n",
       "      <td>0.058639</td>\n",
       "      <td>1.084777</td>\n",
       "      <td>0.696707</td>\n",
       "      <td>-0.766096</td>\n",
       "      <td>-0.045153</td>\n",
       "      <td>0.662046</td>\n",
       "      <td>-0.647555</td>\n",
       "      <td>0.462762</td>\n",
       "      <td>-0.617401</td>\n",
       "      <td>-0.578446</td>\n",
       "      <td>-0.377706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>-1.125430</td>\n",
       "      <td>-0.742834</td>\n",
       "      <td>-0.235994</td>\n",
       "      <td>-0.097729</td>\n",
       "      <td>-0.267132</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>1.631020</td>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.506033</td>\n",
       "      <td>-0.286671</td>\n",
       "      <td>0.347114</td>\n",
       "      <td>-0.337646</td>\n",
       "      <td>0.321922</td>\n",
       "      <td>-0.495215</td>\n",
       "      <td>-0.202751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>-1.198544</td>\n",
       "      <td>0.054829</td>\n",
       "      <td>-0.717960</td>\n",
       "      <td>1.128502</td>\n",
       "      <td>-0.740486</td>\n",
       "      <td>-0.855033</td>\n",
       "      <td>-0.099541</td>\n",
       "      <td>0.878284</td>\n",
       "      <td>-0.312854</td>\n",
       "      <td>-0.082944</td>\n",
       "      <td>-0.972884</td>\n",
       "      <td>-0.442968</td>\n",
       "      <td>-0.379204</td>\n",
       "      <td>-0.656778</td>\n",
       "      <td>-0.249108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.245823</td>\n",
       "      <td>1.087030</td>\n",
       "      <td>0.727674</td>\n",
       "      <td>-0.287521</td>\n",
       "      <td>0.254816</td>\n",
       "      <td>-0.525746</td>\n",
       "      <td>0.820819</td>\n",
       "      <td>0.105950</td>\n",
       "      <td>0.174259</td>\n",
       "      <td>-0.134876</td>\n",
       "      <td>-0.716738</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.059694</td>\n",
       "      <td>-0.352881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-0.649530</td>\n",
       "      <td>-0.300363</td>\n",
       "      <td>0.503389</td>\n",
       "      <td>0.561039</td>\n",
       "      <td>-1.326938</td>\n",
       "      <td>-1.119650</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.674898</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.876242</td>\n",
       "      <td>0.510615</td>\n",
       "      <td>-0.092459</td>\n",
       "      <td>-0.571127</td>\n",
       "      <td>-1.078559</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    2.940031 -1.200982  1.386171  1.421958  1.295752  1.127542 -0.830551   \n",
       "1    2.969031  0.568739 -0.995405 -0.047311  0.065348  0.300497 -1.188035   \n",
       "2    1.991280  0.521885 -0.436549  0.004570 -0.152528 -0.051827 -0.032181   \n",
       "3    0.071584  0.996061 -0.075963  0.183511  0.772674  2.509305  0.796459   \n",
       "4   -0.378382  0.166162  0.388914 -1.702416 -1.438576  1.328583 -0.152559   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147 -0.038565  0.198642  0.312745  0.838248  0.058639  1.084777  0.696707   \n",
       "148 -1.125430 -0.742834 -0.235994 -0.097729 -0.267132  0.020630  1.631020   \n",
       "149 -1.198544  0.054829 -0.717960  1.128502 -0.740486 -0.855033 -0.099541   \n",
       "150 -0.245823  1.087030  0.727674 -0.287521  0.254816 -0.525746  0.820819   \n",
       "151 -0.649530 -0.300363  0.503389  0.561039 -1.326938 -1.119650 -0.003095   \n",
       "\n",
       "            7         8         9        10        11        12        13  \\\n",
       "0    1.265011 -0.948901 -0.650675  0.457350 -1.682913  0.035319 -1.430782   \n",
       "1    0.392371  0.262520 -1.473936  0.133124 -0.383836 -0.231574 -0.033198   \n",
       "2    0.157405 -0.084538  0.317521  0.186401 -0.063512  0.148592  0.760500   \n",
       "3   -1.710631  0.078906  0.619381 -0.470390 -0.409396 -0.884893 -0.360189   \n",
       "4    0.229676 -0.745418 -0.293819  0.358246 -0.725692  0.428501  0.600632   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147 -0.766096 -0.045153  0.662046 -0.647555  0.462762 -0.617401 -0.578446   \n",
       "148  0.505772  0.506033 -0.286671  0.347114 -0.337646  0.321922 -0.495215   \n",
       "149  0.878284 -0.312854 -0.082944 -0.972884 -0.442968 -0.379204 -0.656778   \n",
       "150  0.105950  0.174259 -0.134876 -0.716738  0.015089  0.183705  0.059694   \n",
       "151 -0.674898 -0.005655 -0.876242  0.510615 -0.092459 -0.571127 -1.078559   \n",
       "\n",
       "           14  \n",
       "0   -1.052864  \n",
       "1   -0.238394  \n",
       "2   -0.068546  \n",
       "3    0.075540  \n",
       "4   -0.138775  \n",
       "..        ...  \n",
       "147 -0.377706  \n",
       "148 -0.202751  \n",
       "149 -0.249108  \n",
       "150 -0.352881  \n",
       "151  0.196160  \n",
       "\n",
       "[152 rows x 15 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Including Business Descriptions\n",
    "bd = pd.read_excel(\"/Users/giovanni/Documents/QVF - quantitative framework for valuation multiples computation in mergers and acquisitions/data/10_draft_processing/encoded_business_descriptions_with_pca.xlsx\")\n",
    "bd.columns = bd.columns.astype(str)\n",
    "bd.drop([bd.columns[0]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e24465-f6e3-406f-84aa-aeff000fc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Model Financial Features\n",
    "dataset_features_list: list = [\n",
    "    \"sic_prim\",\n",
    "    \"n_empl_22\",\n",
    "    \"n_publications\",\n",
    "    \"cagr_revs\",\n",
    "    \"cagr_ta\",\n",
    "    \"2y_avg_ta\",\n",
    "    \"ebit_m_22\",\n",
    "    \"ni_m_22\",\n",
    "    \"capex_revs_22\",\n",
    "    \"cagr_capex\",\n",
    "    \"ta_turnover_22\",\n",
    "    \"ca_turnover_22\",\n",
    "    \"cap_intensity_22\",\n",
    "    \"roa_22\",\n",
    "    \"ta_tl_22\",\n",
    "]\n",
    "\n",
    "# Define Financial Feature Dataset\n",
    "feature_datasets: pd.DataFrame = data_frame[dataset_features_list]\n",
    "#feature_datasets.columns = feature_datasets.columns.astype(str)\n",
    "\n",
    "# Including Business Descriptions\n",
    "feature_datasets = pd.concat([feature_datasets, bd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dcb3c2ea-a8cf-40f5-83f4-5793c80a07e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-dimensional Model Target Variable\n",
    "target_variable_name: str = \"ev_sales_22\"\n",
    "target_vector: NDArray = data_frame[target_variable_name].to_numpy()\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "# Normalize numerical features\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "X = scaler.fit_transform(feature_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f3875b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sic_prim</th>\n",
       "      <th>n_empl_22</th>\n",
       "      <th>n_publications</th>\n",
       "      <th>cagr_revs</th>\n",
       "      <th>cagr_ta</th>\n",
       "      <th>2y_avg_ta</th>\n",
       "      <th>ebit_m_22</th>\n",
       "      <th>ni_m_22</th>\n",
       "      <th>capex_revs_22</th>\n",
       "      <th>cagr_capex</th>\n",
       "      <th>...</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3571</td>\n",
       "      <td>164000</td>\n",
       "      <td>157916</td>\n",
       "      <td>0.103848</td>\n",
       "      <td>-0.008986</td>\n",
       "      <td>3.518785e+08</td>\n",
       "      <td>0.302887</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>-0.052982</td>\n",
       "      <td>...</td>\n",
       "      <td>1.127542</td>\n",
       "      <td>-0.830551</td>\n",
       "      <td>1.265011</td>\n",
       "      <td>-0.948901</td>\n",
       "      <td>-0.650675</td>\n",
       "      <td>0.457350</td>\n",
       "      <td>-1.682913</td>\n",
       "      <td>0.035319</td>\n",
       "      <td>-1.430782</td>\n",
       "      <td>-1.052864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7372</td>\n",
       "      <td>221000</td>\n",
       "      <td>274012</td>\n",
       "      <td>0.157741</td>\n",
       "      <td>0.089593</td>\n",
       "      <td>3.493095e+08</td>\n",
       "      <td>0.420043</td>\n",
       "      <td>0.366863</td>\n",
       "      <td>0.120472</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300497</td>\n",
       "      <td>-1.188035</td>\n",
       "      <td>0.392371</td>\n",
       "      <td>0.262520</td>\n",
       "      <td>-1.473936</td>\n",
       "      <td>0.133124</td>\n",
       "      <td>-0.383836</td>\n",
       "      <td>-0.231574</td>\n",
       "      <td>-0.033198</td>\n",
       "      <td>-0.238394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3571</td>\n",
       "      <td>133000</td>\n",
       "      <td>52015</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>-0.053849</td>\n",
       "      <td>9.117300e+07</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.176393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051827</td>\n",
       "      <td>-0.032181</td>\n",
       "      <td>0.157405</td>\n",
       "      <td>-0.084538</td>\n",
       "      <td>0.317521</td>\n",
       "      <td>0.186401</td>\n",
       "      <td>-0.063512</td>\n",
       "      <td>0.148592</td>\n",
       "      <td>0.760500</td>\n",
       "      <td>-0.068546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3724</td>\n",
       "      <td>182000</td>\n",
       "      <td>206529</td>\n",
       "      <td>0.179107</td>\n",
       "      <td>0.043060</td>\n",
       "      <td>1.601340e+08</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.104154</td>\n",
       "      <td>...</td>\n",
       "      <td>2.509305</td>\n",
       "      <td>0.796459</td>\n",
       "      <td>-1.710631</td>\n",
       "      <td>0.078906</td>\n",
       "      <td>0.619381</td>\n",
       "      <td>-0.470390</td>\n",
       "      <td>-0.409396</td>\n",
       "      <td>-0.884893</td>\n",
       "      <td>-0.360189</td>\n",
       "      <td>0.075540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3724</td>\n",
       "      <td>172000</td>\n",
       "      <td>284661</td>\n",
       "      <td>-0.120298</td>\n",
       "      <td>-0.117297</td>\n",
       "      <td>1.938625e+08</td>\n",
       "      <td>-0.004664</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>-0.320156</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328583</td>\n",
       "      <td>-0.152559</td>\n",
       "      <td>0.229676</td>\n",
       "      <td>-0.745418</td>\n",
       "      <td>-0.293819</td>\n",
       "      <td>0.358246</td>\n",
       "      <td>-0.725692</td>\n",
       "      <td>0.428501</td>\n",
       "      <td>0.600632</td>\n",
       "      <td>-0.138775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>3827</td>\n",
       "      <td>88</td>\n",
       "      <td>9</td>\n",
       "      <td>0.017859</td>\n",
       "      <td>0.099436</td>\n",
       "      <td>1.969600e+04</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0.057320</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.113792</td>\n",
       "      <td>...</td>\n",
       "      <td>1.084777</td>\n",
       "      <td>0.696707</td>\n",
       "      <td>-0.766096</td>\n",
       "      <td>-0.045153</td>\n",
       "      <td>0.662046</td>\n",
       "      <td>-0.647555</td>\n",
       "      <td>0.462762</td>\n",
       "      <td>-0.617401</td>\n",
       "      <td>-0.578446</td>\n",
       "      <td>-0.377706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>3533</td>\n",
       "      <td>86</td>\n",
       "      <td>30</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>-0.027028</td>\n",
       "      <td>1.610637e+04</td>\n",
       "      <td>0.094570</td>\n",
       "      <td>0.055774</td>\n",
       "      <td>0.174378</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020630</td>\n",
       "      <td>1.631020</td>\n",
       "      <td>0.505772</td>\n",
       "      <td>0.506033</td>\n",
       "      <td>-0.286671</td>\n",
       "      <td>0.347114</td>\n",
       "      <td>-0.337646</td>\n",
       "      <td>0.321922</td>\n",
       "      <td>-0.495215</td>\n",
       "      <td>-0.202751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>3669</td>\n",
       "      <td>200</td>\n",
       "      <td>11</td>\n",
       "      <td>0.148172</td>\n",
       "      <td>0.071812</td>\n",
       "      <td>5.408350e+04</td>\n",
       "      <td>0.272390</td>\n",
       "      <td>0.171980</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>-0.347916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855033</td>\n",
       "      <td>-0.099541</td>\n",
       "      <td>0.878284</td>\n",
       "      <td>-0.312854</td>\n",
       "      <td>-0.082944</td>\n",
       "      <td>-0.972884</td>\n",
       "      <td>-0.442968</td>\n",
       "      <td>-0.379204</td>\n",
       "      <td>-0.656778</td>\n",
       "      <td>-0.249108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3559</td>\n",
       "      <td>84</td>\n",
       "      <td>134</td>\n",
       "      <td>0.067183</td>\n",
       "      <td>0.133993</td>\n",
       "      <td>1.890012e+04</td>\n",
       "      <td>0.045356</td>\n",
       "      <td>0.042230</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.525746</td>\n",
       "      <td>0.820819</td>\n",
       "      <td>0.105950</td>\n",
       "      <td>0.174259</td>\n",
       "      <td>-0.134876</td>\n",
       "      <td>-0.716738</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>0.059694</td>\n",
       "      <td>-0.352881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3823</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "      <td>0.047652</td>\n",
       "      <td>0.014178</td>\n",
       "      <td>1.396750e+04</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>0.193825</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.119650</td>\n",
       "      <td>-0.003095</td>\n",
       "      <td>-0.674898</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>-0.876242</td>\n",
       "      <td>0.510615</td>\n",
       "      <td>-0.092459</td>\n",
       "      <td>-0.571127</td>\n",
       "      <td>-1.078559</td>\n",
       "      <td>0.196160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>152 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sic_prim  n_empl_22  n_publications  cagr_revs   cagr_ta     2y_avg_ta  \\\n",
       "0        3571     164000          157916   0.103848 -0.008986  3.518785e+08   \n",
       "1        7372     221000          274012   0.157741  0.089593  3.493095e+08   \n",
       "2        3571     133000           52015   0.030772 -0.053849  9.117300e+07   \n",
       "3        3724     182000          206529   0.179107  0.043060  1.601340e+08   \n",
       "4        3724     172000          284661  -0.120298 -0.117297  1.938625e+08   \n",
       "..        ...        ...             ...        ...       ...           ...   \n",
       "147      3827         88               9   0.017859  0.099436  1.969600e+04   \n",
       "148      3533         86              30   0.011482 -0.027028  1.610637e+04   \n",
       "149      3669        200              11   0.148172  0.071812  5.408350e+04   \n",
       "150      3559         84             134   0.067183  0.133993  1.890012e+04   \n",
       "151      3823         35              18   0.047652  0.014178  1.396750e+04   \n",
       "\n",
       "     ebit_m_22   ni_m_22  capex_revs_22  cagr_capex  ...         5         6  \\\n",
       "0     0.302887  0.253096       0.027155   -0.052982  ...  1.127542 -0.830551   \n",
       "1     0.420043  0.366863       0.120472    0.197077  ...  0.300497 -1.188035   \n",
       "2     0.060508  0.023871       0.029355    0.176393  ... -0.051827 -0.032181   \n",
       "3     0.082059  0.077482       0.041372    0.104154  ...  2.509305  0.796459   \n",
       "4    -0.004664  0.000861       0.025543   -0.320156  ...  1.328583 -0.152559   \n",
       "..         ...       ...            ...         ...  ...       ...       ...   \n",
       "147   0.073583  0.057320       0.011482    0.113792  ...  1.084777  0.696707   \n",
       "148   0.094570  0.055774       0.174378    0.453951  ...  0.020630  1.631020   \n",
       "149   0.272390  0.171980       0.018809   -0.347916  ... -0.855033 -0.099541   \n",
       "150   0.045356  0.042230       0.036915    0.003915  ... -0.525746  0.820819   \n",
       "151  -0.004098  0.011075       0.007199    0.193825  ... -1.119650 -0.003095   \n",
       "\n",
       "            7         8         9        10        11        12        13  \\\n",
       "0    1.265011 -0.948901 -0.650675  0.457350 -1.682913  0.035319 -1.430782   \n",
       "1    0.392371  0.262520 -1.473936  0.133124 -0.383836 -0.231574 -0.033198   \n",
       "2    0.157405 -0.084538  0.317521  0.186401 -0.063512  0.148592  0.760500   \n",
       "3   -1.710631  0.078906  0.619381 -0.470390 -0.409396 -0.884893 -0.360189   \n",
       "4    0.229676 -0.745418 -0.293819  0.358246 -0.725692  0.428501  0.600632   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "147 -0.766096 -0.045153  0.662046 -0.647555  0.462762 -0.617401 -0.578446   \n",
       "148  0.505772  0.506033 -0.286671  0.347114 -0.337646  0.321922 -0.495215   \n",
       "149  0.878284 -0.312854 -0.082944 -0.972884 -0.442968 -0.379204 -0.656778   \n",
       "150  0.105950  0.174259 -0.134876 -0.716738  0.015089  0.183705  0.059694   \n",
       "151 -0.674898 -0.005655 -0.876242  0.510615 -0.092459 -0.571127 -1.078559   \n",
       "\n",
       "           14  \n",
       "0   -1.052864  \n",
       "1   -0.238394  \n",
       "2   -0.068546  \n",
       "3    0.075540  \n",
       "4   -0.138775  \n",
       "..        ...  \n",
       "147 -0.377706  \n",
       "148 -0.202751  \n",
       "149 -0.249108  \n",
       "150 -0.352881  \n",
       "151  0.196160  \n",
       "\n",
       "[152 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf607be-2a60-47b8-9ba8-4cfefe487763",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0befbcf-76be-436d-aa26-fa9ba73d1236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 37.77709304811455, STD: 17.69928393546866\n",
      "Average Test MSE: 15758.560127381506, STD: 24246.470206710623\n",
      "Average Test R-squared: -2.5917177144266845, STD: 5.966937757214315\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "rf_maes = []\n",
    "rf_mses = []\n",
    "rf_rsqr = []\n",
    "\n",
    "for iteration in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_grid: dict[str, list[int | None]] = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    # Initialize Random Forest Regressor\n",
    "    cv_rf_regressor: RandomForestRegressor = RandomForestRegressor()\n",
    "\n",
    "    # Grid search with Cross-Validation\n",
    "    grid_search: GridSearchCV = GridSearchCV(\n",
    "        estimator=cv_rf_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    random_forest_model: RandomForestRegressor = RandomForestRegressor(**best_params)\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    test_mae = mean_absolute_error(y_test, random_forest_model.predict(X_test))\n",
    "    rf_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, random_forest_model.predict(X_test))\n",
    "    rf_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, random_forest_model.predict(X_test))\n",
    "    rf_rsqr.append(test_r2)\n",
    "\n",
    "rf_avg_mae = statistics.mean(rf_maes)\n",
    "rf_avg_mse = statistics.mean(rf_mses)\n",
    "rf_avg_r2 = statistics.mean(rf_rsqr)\n",
    "rf_std_mae = statistics.stdev(rf_maes)\n",
    "rf_std_mse = statistics.stdev(rf_mses)\n",
    "rf_std_r2 = statistics.stdev(rf_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {rf_avg_mae}, STD: {rf_std_mae}\")\n",
    "print(f\"Average Test MSE: {rf_avg_mse}, STD: {rf_std_mse}\")\n",
    "print(f\"Average Test R-squared: {rf_avg_r2}, STD: {rf_std_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f2bee-c3f0-43cb-8097-29db606ee210",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973e8285-c84b-4b22-b2ff-c693f59f4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 44.44548191779294, STD: 20.37351138416319\n",
      "Average Test MSE: 34280.530197984335, STD: 37217.899974718726\n",
      "Average Test R-squared: -10.914935585122752, STD: 31.76002818445584\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "gb_maes = []\n",
    "gb_mses = []\n",
    "gb_rsqr = []\n",
    "\n",
    "for rsid in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for XGBoost\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    }\n",
    "\n",
    "    # Initialize XGBoost Regressor\n",
    "    cv_xgb_regressor = XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=cv_xgb_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    xgboost_model = XGBRegressor(**best_params, random_state=42)\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    train_predictions = xgboost_model.predict(X_train)\n",
    "    test_predictions = xgboost_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    gb_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    gb_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    gb_rsqr.append(test_r2)\n",
    "\n",
    "gb_avg_mae = statistics.mean(gb_maes)\n",
    "gb_avg_mse = statistics.mean(gb_mses)\n",
    "gb_avg_r2 = statistics.mean(gb_rsqr)\n",
    "gb_std_mae = statistics.stdev(gb_maes)\n",
    "gb_std_mse = statistics.stdev(gb_mses)\n",
    "gb_std_r2 = statistics.stdev(gb_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {gb_avg_mae}, STD: {gb_std_mae}\")\n",
    "print(f\"Average Test MSE: {gb_avg_mse}, STD: {gb_std_mse}\")\n",
    "print(f\"Average Test R-squared: {gb_avg_r2}, STD: {gb_std_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e68ea7-932a-432f-9b69-0aed28658327",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ac3ae3f-8b6b-4b1d-b2b3-53fa1b66789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 34.3274439911594, STD: 22.256201512489653\n",
      "Average Test MSE: 28246.17293511209, STD: 39402.81390423328\n",
      "Average Test R-squared: -0.026494028212099, STD: 0.0561012208384979\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "svm_maes = []\n",
    "svm_mses = []\n",
    "svm_rsqr = []\n",
    "\n",
    "for rsid in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for SVR\n",
    "    param_grid = {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "\n",
    "    # Initialize SVR\n",
    "    cv_svr_regressor = SVR()\n",
    "\n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=cv_svr_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    svr_model = SVR(**best_params)\n",
    "    svr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    train_predictions = svr_model.predict(X_train)\n",
    "    test_predictions = svr_model.predict(X_test)\n",
    "\n",
    "    # Evaluation\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    svm_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    svm_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    svm_rsqr.append(test_r2)\n",
    "\n",
    "svm_avg_mae = statistics.mean(svm_maes)\n",
    "svm_avg_mse = statistics.mean(svm_mses)\n",
    "svm_avg_r2 = statistics.mean(svm_rsqr)\n",
    "svm_std_mae = statistics.stdev(svm_maes)\n",
    "svm_std_mse = statistics.stdev(svm_mses)\n",
    "svm_std_r2 = statistics.stdev(svm_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {svm_avg_mae}, STD: {svm_std_mae}\")\n",
    "print(f\"Average Test MSE: {svm_avg_mse}, STD: {svm_std_mse}\")\n",
    "print(f\"Average Test R-squared: {svm_avg_r2}, STD: {svm_std_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
