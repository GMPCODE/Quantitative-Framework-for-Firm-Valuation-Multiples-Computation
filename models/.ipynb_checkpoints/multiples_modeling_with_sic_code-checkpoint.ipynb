{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fa65eb",
   "metadata": {},
   "source": [
    "### EV/sales modeling with SIC code and NO business descriptions in input database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad276f",
   "metadata": {},
   "source": [
    "In this script we are going to train different ML models with three main types of architecture: Random Forest, Gradient Boosting, and Support Vector Machine. Our dependent variable is the EV/Sales multiple, and the independent ones are the financial metrics selected from the financial features analysis + the SIC code for each firm, accounting for a qualitative description of the business' operating activity. Each model is trained and tested 50 times with different initialization seeds and hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524994a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f35c79",
   "metadata": {},
   "source": [
    "We are now going to define all the project-related folders and loading out Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d779607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9b86b3-9e7f-455b-88cc-4d812707f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data_folder: Path = Path(\"/Users/giovanni/Documents/QVF - quantitative framework for valuation multiples computation in mergers and acquisitions/data/00_raw\")\n",
    "dataset_excel_file_name: str = (\n",
    "    \"sic_industrial_and_commercial_machinery_and_computer_equipment.xlsx\"\n",
    ")\n",
    "dataset_excel_sheet_reference: str = \"Filtered Results\"\n",
    "\n",
    "# Loading Excel file\n",
    "data_frame: pd.DataFrame = pd.read_excel(\n",
    "    io=data_folder.joinpath(dataset_excel_file_name),\n",
    "    sheet_name=dataset_excel_sheet_reference,\n",
    ")\n",
    "data_frame.columns = data_frame.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d427119-e67b-4625-920e-d95c38899bf4",
   "metadata": {},
   "source": [
    "## Setting independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5e24465-f6e3-406f-84aa-aeff000fc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "# Model Features\n",
    "dataset_features_list: list = [\n",
    "    \"sic_prim\",\n",
    "    \"n_empl_22\",\n",
    "    \"n_publications\",\n",
    "    \"cagr_revs\",\n",
    "    \"cagr_ta\",\n",
    "    \"2y_avg_ta\",\n",
    "    \"ebit_m_22\",\n",
    "    \"ni_m_22\",\n",
    "    \"capex_revs_22\",\n",
    "    \"cagr_capex\",\n",
    "    \"ta_turnover_22\",\n",
    "    \"ca_turnover_22\",\n",
    "    \"cap_intensity_22\",\n",
    "    \"roa_22\",\n",
    "    \"ta_tl_22\",\n",
    "]\n",
    "\n",
    "# Define Feature Dataset\n",
    "feature_datasets: pd.DataFrame = data_frame[dataset_features_list]\n",
    "#feature_datasets.columns = feature_datasets.columns.astype(str)\n",
    "\n",
    "# Setting target variable\n",
    "target_variable_name: str = \"ev_sales_22\"\n",
    "target_vector: NDArray = data_frame[target_variable_name].to_numpy()\n",
    "\n",
    "# Split the data into features (X) and target (y) + normalize numerical features\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "X = scaler.fit_transform(feature_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3875b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sic_prim</th>\n",
       "      <th>n_empl_22</th>\n",
       "      <th>n_publications</th>\n",
       "      <th>cagr_revs</th>\n",
       "      <th>cagr_ta</th>\n",
       "      <th>2y_avg_ta</th>\n",
       "      <th>ebit_m_22</th>\n",
       "      <th>ni_m_22</th>\n",
       "      <th>capex_revs_22</th>\n",
       "      <th>cagr_capex</th>\n",
       "      <th>ta_turnover_22</th>\n",
       "      <th>ca_turnover_22</th>\n",
       "      <th>cap_intensity_22</th>\n",
       "      <th>roa_22</th>\n",
       "      <th>ta_tl_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3571</td>\n",
       "      <td>164000</td>\n",
       "      <td>157916</td>\n",
       "      <td>0.103848</td>\n",
       "      <td>-0.008986</td>\n",
       "      <td>3.518785e+08</td>\n",
       "      <td>0.302887</td>\n",
       "      <td>0.253096</td>\n",
       "      <td>0.027155</td>\n",
       "      <td>-0.052982</td>\n",
       "      <td>1.117852</td>\n",
       "      <td>2.912212</td>\n",
       "      <td>0.964294</td>\n",
       "      <td>0.282924</td>\n",
       "      <td>1.167742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7372</td>\n",
       "      <td>221000</td>\n",
       "      <td>274012</td>\n",
       "      <td>0.157741</td>\n",
       "      <td>0.089593</td>\n",
       "      <td>3.493095e+08</td>\n",
       "      <td>0.420043</td>\n",
       "      <td>0.366863</td>\n",
       "      <td>0.120472</td>\n",
       "      <td>0.197077</td>\n",
       "      <td>0.543444</td>\n",
       "      <td>1.168466</td>\n",
       "      <td>2.170530</td>\n",
       "      <td>0.199370</td>\n",
       "      <td>1.839857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3571</td>\n",
       "      <td>133000</td>\n",
       "      <td>52015</td>\n",
       "      <td>0.030772</td>\n",
       "      <td>-0.053849</td>\n",
       "      <td>9.117300e+07</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>0.023871</td>\n",
       "      <td>0.029355</td>\n",
       "      <td>0.176393</td>\n",
       "      <td>1.141612</td>\n",
       "      <td>2.415551</td>\n",
       "      <td>0.885510</td>\n",
       "      <td>0.027251</td>\n",
       "      <td>0.966333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3724</td>\n",
       "      <td>182000</td>\n",
       "      <td>206529</td>\n",
       "      <td>0.179107</td>\n",
       "      <td>0.043060</td>\n",
       "      <td>1.601340e+08</td>\n",
       "      <td>0.082059</td>\n",
       "      <td>0.077482</td>\n",
       "      <td>0.041372</td>\n",
       "      <td>0.104154</td>\n",
       "      <td>0.422210</td>\n",
       "      <td>1.580331</td>\n",
       "      <td>2.467292</td>\n",
       "      <td>0.032714</td>\n",
       "      <td>1.842286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3724</td>\n",
       "      <td>172000</td>\n",
       "      <td>284661</td>\n",
       "      <td>-0.120298</td>\n",
       "      <td>-0.117297</td>\n",
       "      <td>1.938625e+08</td>\n",
       "      <td>-0.004664</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>-0.320156</td>\n",
       "      <td>0.307645</td>\n",
       "      <td>0.995119</td>\n",
       "      <td>3.344331</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1.217176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>7371</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.074816</td>\n",
       "      <td>0.228730</td>\n",
       "      <td>9.254000e+03</td>\n",
       "      <td>-2.162704</td>\n",
       "      <td>-2.155532</td>\n",
       "      <td>0.196440</td>\n",
       "      <td>0.644956</td>\n",
       "      <td>0.811752</td>\n",
       "      <td>1.388602</td>\n",
       "      <td>1.274564</td>\n",
       "      <td>-1.749757</td>\n",
       "      <td>0.687546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>3679</td>\n",
       "      <td>350</td>\n",
       "      <td>1749</td>\n",
       "      <td>-0.559323</td>\n",
       "      <td>0.494800</td>\n",
       "      <td>1.226105e+05</td>\n",
       "      <td>-81.159639</td>\n",
       "      <td>-79.956325</td>\n",
       "      <td>6.564759</td>\n",
       "      <td>0.405194</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>45.998400</td>\n",
       "      <td>-0.461677</td>\n",
       "      <td>4.553395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>3519</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.026281</td>\n",
       "      <td>0.325932</td>\n",
       "      <td>5.439575e+04</td>\n",
       "      <td>-9.733878</td>\n",
       "      <td>-9.724274</td>\n",
       "      <td>0.037424</td>\n",
       "      <td>0.208634</td>\n",
       "      <td>0.134532</td>\n",
       "      <td>0.245627</td>\n",
       "      <td>16.390755</td>\n",
       "      <td>-1.308224</td>\n",
       "      <td>22.491748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>3589</td>\n",
       "      <td>16</td>\n",
       "      <td>222</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>0.148741</td>\n",
       "      <td>4.393500e+03</td>\n",
       "      <td>-2.009714</td>\n",
       "      <td>-1.883972</td>\n",
       "      <td>0.043713</td>\n",
       "      <td>0.242372</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.479555</td>\n",
       "      <td>1.141839</td>\n",
       "      <td>-0.778546</td>\n",
       "      <td>7.798261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3585</td>\n",
       "      <td>21</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.049573</td>\n",
       "      <td>0.192432</td>\n",
       "      <td>9.473950e+02</td>\n",
       "      <td>-1.639070</td>\n",
       "      <td>-3.949710</td>\n",
       "      <td>0.040060</td>\n",
       "      <td>-0.067999</td>\n",
       "      <td>1.420025</td>\n",
       "      <td>1.858424</td>\n",
       "      <td>1.878512</td>\n",
       "      <td>-5.608689</td>\n",
       "      <td>0.060016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sic_prim  n_empl_22  n_publications  cagr_revs   cagr_ta     2y_avg_ta  \\\n",
       "0        3571     164000          157916   0.103848 -0.008986  3.518785e+08   \n",
       "1        7372     221000          274012   0.157741  0.089593  3.493095e+08   \n",
       "2        3571     133000           52015   0.030772 -0.053849  9.117300e+07   \n",
       "3        3724     182000          206529   0.179107  0.043060  1.601340e+08   \n",
       "4        3724     172000          284661  -0.120298 -0.117297  1.938625e+08   \n",
       "..        ...        ...             ...        ...       ...           ...   \n",
       "210      7371         67               3  -0.074816  0.228730  9.254000e+03   \n",
       "211      3679        350            1749  -0.559323  0.494800  1.226105e+05   \n",
       "212      3519         13               6  -0.026281  0.325932  5.439575e+04   \n",
       "213      3589         16             222   0.010952  0.148741  4.393500e+03   \n",
       "214      3585         21              96  -0.049573  0.192432  9.473950e+02   \n",
       "\n",
       "     ebit_m_22    ni_m_22  capex_revs_22  cagr_capex  ta_turnover_22  \\\n",
       "0     0.302887   0.253096       0.027155   -0.052982        1.117852   \n",
       "1     0.420043   0.366863       0.120472    0.197077        0.543444   \n",
       "2     0.060508   0.023871       0.029355    0.176393        1.141612   \n",
       "3     0.082059   0.077482       0.041372    0.104154        0.422210   \n",
       "4    -0.004664   0.000861       0.025543   -0.320156        0.307645   \n",
       "..         ...        ...            ...         ...             ...   \n",
       "210  -2.162704  -2.155532       0.196440    0.644956        0.811752   \n",
       "211 -81.159639 -79.956325       6.564759    0.405194        0.005774   \n",
       "212  -9.733878  -9.724274       0.037424    0.208634        0.134532   \n",
       "213  -2.009714  -1.883972       0.043713    0.242372        0.413247   \n",
       "214  -1.639070  -3.949710       0.040060   -0.067999        1.420025   \n",
       "\n",
       "     ca_turnover_22  cap_intensity_22    roa_22   ta_tl_22  \n",
       "0          2.912212          0.964294  0.282924   1.167742  \n",
       "1          1.168466          2.170530  0.199370   1.839857  \n",
       "2          2.415551          0.885510  0.027251   0.966333  \n",
       "3          1.580331          2.467292  0.032714   1.842286  \n",
       "4          0.995119          3.344331  0.000265   1.217176  \n",
       "..              ...               ...       ...        ...  \n",
       "210        1.388602          1.274564 -1.749757   0.687546  \n",
       "211        0.007296         45.998400 -0.461677   4.553395  \n",
       "212        0.245627         16.390755 -1.308224  22.491748  \n",
       "213        0.479555          1.141839 -0.778546   7.798261  \n",
       "214        1.858424          1.878512 -5.608689   0.060016  \n",
       "\n",
       "[215 rows x 15 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf607be-2a60-47b8-9ba8-4cfefe487763",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0befbcf-76be-436d-aa26-fa9ba73d1236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 2.907438048776477, STD: 3.381915463696909\n",
      "Average Test MSE: 779.3685789266142, STD: 1558.6961619505246\n",
      "Average Test R-squared: -0.40819254761673973, STD: 2.7361054568747374\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "rf_maes = []\n",
    "rf_mses = []\n",
    "rf_rsqr = []\n",
    "\n",
    "for iteration in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for Random Forest\n",
    "    param_grid: dict[str, list[int | None]] = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "\n",
    "    # Initialize Random Forest\n",
    "    cv_rf_regressor: RandomForestRegressor = RandomForestRegressor()\n",
    "\n",
    "    # Grid search with Cross-Validation\n",
    "    grid_search: GridSearchCV = GridSearchCV(\n",
    "        estimator=cv_rf_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    random_forest_model: RandomForestRegressor = RandomForestRegressor(**best_params)\n",
    "    random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "    # TEST Evaluation\n",
    "    test_mae = mean_absolute_error(y_test, random_forest_model.predict(X_test))\n",
    "    rf_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, random_forest_model.predict(X_test))\n",
    "    rf_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, random_forest_model.predict(X_test))\n",
    "    rf_rsqr.append(test_r2)\n",
    "\n",
    "rf_avg_mae = statistics.mean(rf_maes)\n",
    "rf_avg_mse = statistics.mean(rf_mses)\n",
    "rf_avg_r2 = statistics.mean(rf_rsqr)\n",
    "rf_std_mae = statistics.stdev(rf_maes)\n",
    "rf_std_mse = statistics.stdev(rf_mses)\n",
    "rf_std_r2 = statistics.stdev(rf_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {rf_avg_mae}, STD: {rf_std_mae}\")\n",
    "print(f\"Average Test MSE: {rf_avg_mse}, STD: {rf_std_mse}\")\n",
    "print(f\"Average Test R-squared: {rf_avg_r2}, STD: {rf_std_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23018ba1-c6be-4b51-9547-970c0e792617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Target Variable: [ 6.61826109  9.36530497  1.0338057   2.40932298  1.6980636   2.78031469\n",
      "  2.87742336  3.59428747 10.16211047  0.7348095   0.70227386  1.44255545\n",
      "  2.28789393  3.39375028  2.39750572  2.95747068  3.9512269   3.47543958\n",
      "  1.21284456  3.00435251  3.47670873  1.08553623  2.34940028  4.77588495\n",
      "  2.32770475  1.80197236  4.9237651   0.70926634  4.53634023  1.35902067\n",
      "  2.27063932  1.93853424  2.95998462  1.0058872   2.56761208  0.56130329\n",
      "  1.65360307  2.98097282  2.78411732  4.10421003  6.73181521  2.2779393\n",
      "  0.9212265   4.00391035  2.02782298  1.93591711  3.379334    2.59505781\n",
      "  2.31405453  1.4525825   2.25818415  1.50526412  2.76697804  2.42341677\n",
      "  1.86410544  1.83537683  1.60530039  4.05351378  1.75398831  5.08955643\n",
      "  4.98578953  2.35664362  1.90558977  2.27366289  3.9322936   0.98781165\n",
      "  2.23236427  3.09282594  2.33303957  1.75344038  2.94298076  4.31692437\n",
      "  2.01903225  1.14346568  1.37651915  5.35925019  1.59092086  2.00223857\n",
      "  4.46712149  1.16645673  1.38949658  2.21951787  2.41180145  5.99302428\n",
      "  4.24148388  1.29922473  1.79196843  1.9444598   4.02545449  0.79962449\n",
      "  2.49183633  3.96040657  2.77258817  0.69509768  4.03447073  3.24722753\n",
      "  2.9378501   2.2778657   1.85433639  1.53425555  7.48041563  4.01867715\n",
      "  0.9141375   4.15128407  0.79281902  2.10854506  1.75310106  1.13969004\n",
      "  0.4891756   1.98870826  1.71796423  2.69374312  1.79105493  2.00567375\n",
      "  1.05312749  1.74316502  4.56819384  0.81573074  0.79048923  1.47897964\n",
      "  1.46824804  2.45905389  1.07390348  3.19095711  1.07981003  2.29575122\n",
      "  4.80554866  1.0113031   0.44206028  3.47991459  0.46469979  0.64639037\n",
      "  1.18073628  1.34072307  0.94088355  0.82411293  0.85064916  6.59032629\n",
      "  1.31095285  1.43341624  0.47626112  0.6393892   0.37955443  0.92747094\n",
      "  3.68294378  0.76658588  1.23724015  1.01949588  1.53673221  2.2736694\n",
      "  2.60769563  0.92577285]\n"
     ]
    }
   ],
   "source": [
    "# Predict y using the trained model\n",
    "predicted_y = random_forest_model.predict(X)\n",
    "\n",
    "print(f\"Predicted Target Variable: {predicted_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f2bee-c3f0-43cb-8097-29db606ee210",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "973e8285-c84b-4b22-b2ff-c693f59f4b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 4.160340231447927, STD: 3.41603224442729\n",
      "Average Test MSE: 1077.4946572103493, STD: 1668.3511573058925\n",
      "Average Test R-squared: -81.81490779252186, STD: 287.7189316520744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "gb_maes = []\n",
    "gb_mses = []\n",
    "gb_rsqr = []\n",
    "\n",
    "for rsid in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for XGBoost\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 5, 7],\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    }\n",
    "\n",
    "    # Initialize XGBoost\n",
    "    cv_xgb_regressor = XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=cv_xgb_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_squared_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    xgboost_model = XGBRegressor(**best_params, random_state=42)\n",
    "    xgboost_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    train_predictions = xgboost_model.predict(X_train)\n",
    "    test_predictions = xgboost_model.predict(X_test)\n",
    "\n",
    "    # TEST Evaluation\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    gb_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    gb_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    gb_rsqr.append(test_r2)\n",
    "\n",
    "gb_avg_mae = statistics.mean(gb_maes)\n",
    "gb_avg_mse = statistics.mean(gb_mses)\n",
    "gb_avg_r2 = statistics.mean(gb_rsqr)\n",
    "gb_std_mae = statistics.stdev(gb_maes)\n",
    "gb_std_mse = statistics.stdev(gb_mses)\n",
    "gb_std_r2 = statistics.stdev(gb_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {gb_avg_mae}, STD: {gb_std_mae}\")\n",
    "print(f\"Average Test MSE: {gb_avg_mse}, STD: {gb_std_mse}\")\n",
    "print(f\"Average Test R-squared: {gb_avg_r2}, STD: {gb_std_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa1d4f1-b74a-40c0-b789-b2306abb8263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Target Variable: [4.220229  4.220229  1.4435946 2.1104164 1.4518372 2.3864708 2.4026008\n",
      " 2.2463183 3.9871473 1.4055482 1.2756628 1.6751648 2.0559688 2.6951225\n",
      " 2.096041  2.3339667 2.6951225 3.5347645 1.4482124 2.2323773 3.5347645\n",
      " 1.735531  2.2400284 2.6951225 2.079911  2.2200634 5.199701  1.4540391\n",
      " 2.4741192 1.4056908 2.2463183 2.0492544 2.36959   1.4681818 2.1675596\n",
      " 1.2756628 2.0516913 2.3864708 2.307712  5.4705915 5.015082  2.1836896\n",
      " 1.328322  2.6436265 1.8494046 1.8651943 2.7435849 2.307712  2.1938818\n",
      " 1.5354208 1.9818792 1.328322  2.4341807 2.079911  1.8651719 1.8429699\n",
      " 1.9890797 5.248163  1.9218837 4.2686915 2.1675596 2.0294845 1.9745307\n",
      " 2.0877402 4.2686915 1.4012156 2.0441606 2.2463183 1.7603837 2.0908713\n",
      " 2.307712  4.146424  2.1995115 1.3238468 1.5259386 3.946886  2.0360765\n",
      " 2.0131998 4.220229  1.4585143 1.5125935 2.1192503 2.2624483 5.23751\n",
      " 2.509939  1.5619367 1.8230263 1.8093265 2.4584424 1.336893  2.3864708\n",
      " 3.1856637 2.3339667 1.2472839 2.509939  2.5253742 2.3339667 2.2586536\n",
      " 2.1603103 1.8858253 5.4705915 2.9108253 1.295468  2.509939  1.4256603\n",
      " 2.4584424 1.8651943 1.2995751 1.2472839 2.0639958 1.8393929 2.4472337\n",
      " 1.8398554 2.1436172 1.3238468 1.4943588 2.509939  1.295468  1.2472839\n",
      " 1.5393933 1.8766905 2.2200634 1.3279539 2.4741192 1.3510357 1.924464\n",
      " 2.4584424 1.3279539 1.295468  2.4902492 1.295468  1.2570535 1.4437371\n",
      " 1.9238431 1.3794146 1.385443  1.2756628 3.946886  1.932377  1.7293075\n",
      " 1.3085141 1.295468  1.295468  2.1372318 2.4584424 1.295468  1.2599914\n",
      " 1.3894366 2.0291824 2.3826845 2.4978135 2.0267885]\n"
     ]
    }
   ],
   "source": [
    "# Predict y for the new set of features using the trained XGBoost model\n",
    "predicted_y = xgboost_model.predict(X)\n",
    "\n",
    "print(f\"Predicted Target Variable: {predicted_y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e68ea7-932a-432f-9b69-0aed28658327",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac3ae3f-8b6b-4b1d-b2b3-53fa1b66789d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test MAE: 4.094211787648164, STD: 3.7459421299139013\n",
      "Average Test MSE: 1172.9510606345966, STD: 1790.0465201915392\n",
      "Average Test R-squared: -1.5841380349857772, STD: 3.1831455587211726\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "svm_maes = []\n",
    "svm_mses = []\n",
    "svm_rsqr = []\n",
    "\n",
    "for rsid in range(50):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        target_vector,\n",
    "        test_size=0.25,\n",
    "    )\n",
    "\n",
    "    # Define the parameter grid for SVR\n",
    "    param_grid = {\n",
    "        \"kernel\": [\"linear\", \"poly\", \"rbf\"],\n",
    "        \"C\": [0.1, 1, 10],\n",
    "        \"gamma\": [\"scale\", \"auto\"],\n",
    "    }\n",
    "\n",
    "    # Initialize SVR\n",
    "    cv_svr_regressor = SVR()\n",
    "\n",
    "    # Grid search with cross-validation\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=cv_svr_regressor,\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        scoring=\"neg_mean_absolute_error\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    svr_model = SVR(**best_params)\n",
    "    svr_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    train_predictions = svr_model.predict(X_train)\n",
    "    test_predictions = svr_model.predict(X_test)\n",
    "\n",
    "    # TEST Evaluation\n",
    "    test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "    svm_maes.append(test_mae)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, test_predictions)\n",
    "    svm_mses.append(test_mse)\n",
    "\n",
    "    test_r2 = r2_score(y_test, test_predictions)\n",
    "    svm_rsqr.append(test_r2)\n",
    "\n",
    "svm_avg_mae = statistics.mean(svm_maes)\n",
    "svm_avg_mse = statistics.mean(svm_mses)\n",
    "svm_avg_r2 = statistics.mean(svm_rsqr)\n",
    "svm_std_mae = statistics.stdev(svm_maes)\n",
    "svm_std_mse = statistics.stdev(svm_mses)\n",
    "svm_std_r2 = statistics.stdev(svm_rsqr)\n",
    "\n",
    "print(f\"Average Test MAE: {svm_avg_mae}, STD: {svm_std_mae}\")\n",
    "print(f\"Average Test MSE: {svm_avg_mse}, STD: {svm_std_mse}\")\n",
    "print(f\"Average Test R-squared: {svm_avg_r2}, STD: {svm_std_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a555944c-863f-495c-8d14-4631876b8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Target Variable: [ 5.90759251e+00  9.58598092e+00  2.11856066e+00  2.49490881e+00\n",
      "  1.74951658e+00  2.21014625e+00  2.70171121e+00  3.86060683e+00\n",
      "  3.78116122e+00  1.04581697e+00  8.90911076e-01  1.81369176e+00\n",
      "  3.38463164e+00  3.15678143e+00  2.50126961e+00  2.57938153e+00\n",
      "  3.40968902e+00  2.62494823e+00  1.17217647e+00  2.41308912e+00\n",
      "  4.29284954e+00  1.73888388e+00  1.24907026e+00  3.73615915e+00\n",
      "  2.58525414e+00  2.22304563e+00  3.39353556e+00  4.56830027e-01\n",
      "  3.28095267e+00  6.64697842e-01  2.51291284e+00  1.58695901e+00\n",
      "  2.95106146e+00  1.44958166e+00  3.55106263e+00 -1.21223014e-01\n",
      "  1.96245592e+00  3.49671423e+00  3.05936237e+00  6.32135934e+00\n",
      "  3.34635444e+00  2.70839441e+00  1.18195627e+00  2.49998960e+00\n",
      "  2.05877289e+00  1.71251884e+00  2.45733252e+00  2.69325185e+00\n",
      "  1.58099005e+00  1.78735736e+00  1.15470789e+00  1.68291010e+00\n",
      "  2.07427728e+00  2.32420328e+00  2.11990011e+00  1.28749979e+00\n",
      "  1.64366572e+00  4.03487370e+00  1.47391804e+00  3.54091510e+00\n",
      "  4.32217283e+00  2.39262460e+00  2.01903677e+00  2.17310636e+00\n",
      "  4.38224077e+00  8.54608035e-01  2.30174053e+00  2.99576784e+00\n",
      "  1.52669902e+00  2.11662112e+00  3.19415764e+00  3.74957012e+00\n",
      "  2.41883563e+00  8.03411153e-01  1.34466033e+00  3.11886995e+00\n",
      "  1.08972547e+00  1.83680304e+00  2.98361161e+00  1.49247443e+00\n",
      "  1.46220502e+00  1.71686690e+00  1.75617583e+00  5.09327599e+00\n",
      "  2.64790323e+00  4.95528526e-01  2.81328662e+00  2.41017504e+00\n",
      "  2.31452799e+00  1.83264752e-01  2.31533323e+00  3.65146524e+00\n",
      "  2.74466613e+00  3.91027846e-01  4.67023919e+00  2.80581298e+00\n",
      "  2.52754441e+00  2.75044891e+00  1.59735651e+00  1.62786952e+00\n",
      "  7.53212355e+00  2.90916724e+00  1.20047991e+00  3.43278472e+00\n",
      "  5.34408585e-01  2.52006566e+00  1.60241006e+00  6.60467980e-01\n",
      "  4.34244827e-03  1.47536002e+00  1.53627024e+00  3.91560625e+00\n",
      "  1.45989965e+00  2.20878915e+00  7.29715794e-01  6.07281999e-01\n",
      "  3.62080605e+00  7.09786172e-01 -4.78261086e-01  1.99017767e+00\n",
      "  1.54462250e+00  2.69656844e+00  9.96957847e-01  3.02051712e+00\n",
      "  5.74335593e-01  4.04062351e+00  4.02685918e+00  4.04822417e-01\n",
      "  1.51088217e-01  2.74088258e+00  8.45904547e-01  2.51552636e-01\n",
      "  1.04692757e+00  1.22914388e+00  9.45006376e-01  8.10284246e-01\n",
      "  9.52557377e-01  2.29792228e+00  1.48805382e+00  1.17305045e+00\n",
      "  4.94177614e-01  1.29957655e+00  3.59142614e-01  9.26896339e-01\n",
      "  6.86293935e+00  1.09663856e+00  1.02295902e+00  8.58362237e-01\n",
      "  1.21673480e+00  2.39215336e+00  5.41835855e-01 -4.55965126e-01]\n"
     ]
    }
   ],
   "source": [
    "# Predict y for the new set of features using the trained SVR model\n",
    "predicted_y = svr_model.predict(X)\n",
    "\n",
    "print(f\"Predicted Target Variable: {predicted_y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af5e0867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,721</span> (338.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m86,721\u001b[0m (338.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">86,721</span> (338.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m86,721\u001b[0m (338.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "input_shape: int = (feature_datasets.shape[1],)\n",
    "\n",
    "input_layer = layers.Input(shape=input_shape)\n",
    "\n",
    "layer = layers.Dense(64, activation=\"linear\")(input_layer)\n",
    "layer = layers.Dense(128, activation=\"linear\")(layer)\n",
    "layer = layers.Dense(256, activation=\"linear\")(layer)\n",
    "layer = layers.Dense(128, activation=\"relu\")(layer)\n",
    "layer = layers.Dense(64, activation=\"relu\")(layer)\n",
    "layer = layers.Dense(32, activation=\"linear\")(layer)\n",
    "\n",
    "output_layer = layers.Dense(1, activation=\"linear\")(layer)\n",
    "\n",
    "nn_model = keras.Model(input_layer, output_layer)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8d10af",
   "metadata": {},
   "source": [
    "Let's define the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3595700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    target_vector,\n",
    "    test_size=0.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1093e6e",
   "metadata": {},
   "source": [
    "Let's save the model information into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11079142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "nn_model_path: Path = Path(\"model_figure/\")\n",
    "nn_model_name: str = f\"nn_model_{np.random.randint(1, 1000)}.png\"\n",
    "plot_model(nn_model, to_file=nn_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 12.5815 - mae: 2.5232 - mse: 11.9969  \n",
      "Epoch 2/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.3526 - mae: 2.4494 - mse: 11.2360\n",
      "Epoch 3/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.2572 - mae: 2.4601 - mse: 10.7062\n",
      "Epoch 4/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.9941 - mae: 2.3590 - mse: 11.2260\n",
      "Epoch 5/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.6017 - mae: 2.2640 - mse: 10.2602\n",
      "Epoch 6/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3765 - mae: 2.3862 - mse: 10.4510\n",
      "Epoch 7/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3695 - mae: 2.4620 - mse: 11.4021\n",
      "Epoch 8/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6971 - mae: 2.4493 - mse: 11.0208\n",
      "Epoch 9/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.0204 - mae: 2.5516 - mse: 12.0401 \n",
      "Epoch 10/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.4017 - mae: 2.4753 - mse: 11.6899 \n",
      "Epoch 11/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.2390 - mae: 2.4494 - mse: 13.2786 \n",
      "Epoch 12/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.7960 - mae: 2.5291 - mse: 14.0134 \n",
      "Epoch 13/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.7442 - mae: 2.5718 - mse: 13.9619 \n",
      "Epoch 14/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.4062 - mae: 2.5174 - mse: 11.6885 \n",
      "Epoch 15/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0282 - mae: 2.3066 - mse: 11.0216\n",
      "Epoch 16/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0907 - mae: 2.3748 - mse: 11.1384\n",
      "Epoch 17/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.4607 - mae: 2.5851 - mse: 14.5703\n",
      "Epoch 18/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7193 - mae: 2.2474 - mse: 9.5130\n",
      "Epoch 19/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7237 - mae: 2.3063 - mse: 9.9380 \n",
      "Epoch 20/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.3322 - mae: 2.6060 - mse: 14.6084\n",
      "Epoch 21/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.9894 - mae: 2.6657 - mse: 14.3744 \n",
      "Epoch 22/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6292 - mae: 2.4338 - mse: 12.7336 \n",
      "Epoch 23/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.5507 - mae: 2.5063 - mse: 11.7177 \n",
      "Epoch 24/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6805 - mae: 2.3849 - mse: 12.3026 \n",
      "Epoch 25/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7953 - mae: 2.3210 - mse: 10.8105\n",
      "Epoch 26/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.1744 - mae: 2.5384 - mse: 11.0892 \n",
      "Epoch 27/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.0539 - mae: 2.3220 - mse: 10.3075\n",
      "Epoch 28/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.0698 - mae: 2.4719 - mse: 13.2860 \n",
      "Epoch 29/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4558 - mae: 2.3828 - mse: 10.6081\n",
      "Epoch 30/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2630 - mae: 2.3968 - mse: 11.4282\n",
      "Epoch 31/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.4532 - mae: 2.4328 - mse: 12.7065 \n",
      "Epoch 32/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.2815 - mae: 2.6433 - mse: 13.5491 \n",
      "Epoch 33/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.4358 - mae: 2.6327 - mse: 14.5508 \n",
      "Epoch 34/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9060 - mae: 2.4672 - mse: 11.2142\n",
      "Epoch 35/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.2436 - mae: 2.6483 - mse: 14.5539 \n",
      "Epoch 36/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4366 - mae: 2.2924 - mse: 10.5710\n",
      "Epoch 37/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7075 - mae: 2.2947 - mse: 10.8030\n",
      "Epoch 38/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.1660 - mae: 2.4343 - mse: 11.2054\n",
      "Epoch 39/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6608 - mae: 2.5246 - mse: 12.7182 \n",
      "Epoch 40/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14.1248 - mae: 2.6080 - mse: 14.2189 \n",
      "Epoch 41/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4024 - mae: 2.2956 - mse: 10.4151\n",
      "Epoch 42/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0863 - mae: 2.3927 - mse: 10.2564\n",
      "Epoch 43/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4629 - mae: 2.3070 - mse: 10.5043\n",
      "Epoch 44/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.2473 - mae: 2.7069 - mse: 14.4832 \n",
      "Epoch 45/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2578 - mae: 2.4527 - mse: 11.4269 \n",
      "Epoch 46/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7487 - mae: 2.2132 - mse: 9.1568\n",
      "Epoch 47/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8379 - mae: 2.3318 - mse: 11.0011\n",
      "Epoch 48/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8741 - mae: 2.3836 - mse: 10.3998\n",
      "Epoch 49/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8906 - mae: 2.4594 - mse: 12.7999 \n",
      "Epoch 50/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.0099 - mae: 2.3751 - mse: 11.2315\n",
      "Epoch 51/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.1177 - mae: 2.5907 - mse: 12.3811 \n",
      "Epoch 52/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.3273 - mae: 2.6136 - mse: 13.6814 \n",
      "Epoch 53/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5779 - mae: 2.5489 - mse: 12.7047 \n",
      "Epoch 54/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8867 - mae: 2.4762 - mse: 13.1956 \n",
      "Epoch 55/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0720 - mae: 2.4514 - mse: 10.6437 \n",
      "Epoch 56/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.2507 - mae: 2.3711 - mse: 10.2536\n",
      "Epoch 57/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.7274 - mae: 2.5746 - mse: 13.9117 \n",
      "Epoch 58/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5891 - mae: 2.4357 - mse: 11.6169\n",
      "Epoch 59/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.7127 - mae: 2.6343 - mse: 14.0163 \n",
      "Epoch 60/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3053 - mae: 2.3754 - mse: 11.4507\n",
      "Epoch 61/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3274 - mae: 2.3370 - mse: 10.4071\n",
      "Epoch 62/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5977 - mae: 2.4282 - mse: 12.5109 \n",
      "Epoch 63/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.1417 - mae: 2.5056 - mse: 13.3322 \n",
      "Epoch 64/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5835 - mae: 2.3031 - mse: 9.8540 \n",
      "Epoch 65/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.2679 - mae: 2.6310 - mse: 14.3530 \n",
      "Epoch 66/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7325 - mae: 2.2518 - mse: 9.1592 \n",
      "Epoch 67/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4082 - mae: 2.3602 - mse: 10.3674\n",
      "Epoch 68/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9246 - mae: 2.3112 - mse: 10.0720\n",
      "Epoch 69/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.4392 - mae: 2.6501 - mse: 14.7142 \n",
      "Epoch 70/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 10.5762 - mae: 2.3796 - mse: 10.8817\n",
      "Epoch 71/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1895 - mae: 2.3544 - mse: 11.2537\n",
      "Epoch 72/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.4472 - mae: 2.4366 - mse: 12.6923 \n",
      "Epoch 73/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.2132 - mae: 2.4335 - mse: 11.2571 \n",
      "Epoch 74/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8939 - mae: 2.2955 - mse: 11.8365 \n",
      "Epoch 75/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3366 - mae: 2.3547 - mse: 10.1832\n",
      "Epoch 76/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.5525 - mae: 2.4475 - mse: 12.4300 \n",
      "Epoch 77/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2249 - mae: 2.4642 - mse: 11.4669 \n",
      "Epoch 78/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.1086 - mae: 2.5205 - mse: 12.3107 \n",
      "Epoch 79/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.2618 - mae: 2.3643 - mse: 10.5288\n",
      "Epoch 80/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.3386 - mae: 2.5046 - mse: 13.4656 \n",
      "Epoch 81/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5351 - mae: 2.3574 - mse: 9.8403  \n",
      "Epoch 82/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1574 - mae: 2.2800 - mse: 11.0389\n",
      "Epoch 83/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8244 - mae: 2.3416 - mse: 10.1636\n",
      "Epoch 84/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.2935 - mae: 2.6719 - mse: 14.5165 \n",
      "Epoch 85/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.3451 - mae: 2.5779 - mse: 13.6723 \n",
      "Epoch 86/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0188 - mae: 2.4245 - mse: 10.5584 \n",
      "Epoch 87/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3945 - mae: 2.2281 - mse: 9.3251 \n",
      "Epoch 88/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.6994 - mae: 2.4358 - mse: 11.7899 \n",
      "Epoch 89/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 11.1214 - mae: 2.3972 - mse: 11.3023\n",
      "Epoch 90/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4663 - mae: 2.4395 - mse: 10.8477\n",
      "Epoch 91/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.2356 - mae: 2.5232 - mse: 13.4827 \n",
      "Epoch 92/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8939 - mae: 2.4640 - mse: 12.9350 \n",
      "Epoch 93/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.1513 - mae: 2.5418 - mse: 13.4804 \n",
      "Epoch 94/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.3132 - mae: 2.4339 - mse: 12.5814 \n",
      "Epoch 95/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.3766 - mae: 2.5649 - mse: 13.5899 \n",
      "Epoch 96/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1427 - mae: 2.2498 - mse: 10.0517\n",
      "Epoch 97/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.2725 - mae: 2.2843 - mse: 9.7160\n",
      "Epoch 98/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.5228 - mae: 2.5148 - mse: 13.5793 \n",
      "Epoch 99/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7012 - mae: 2.3240 - mse: 10.1755 \n",
      "Epoch 100/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5968 - mae: 2.3948 - mse: 10.6776 \n",
      "Epoch 101/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1656 - mae: 2.2272 - mse: 8.6430 \n",
      "Epoch 102/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8416 - mae: 2.1542 - mse: 9.1572 \n",
      "Epoch 103/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6068 - mae: 2.1454 - mse: 8.7781 \n",
      "Epoch 104/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.9378 - mae: 2.4478 - mse: 13.1338 \n",
      "Epoch 105/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 10.3166 - mae: 2.3351 - mse: 9.6364\n",
      "Epoch 106/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8686 - mae: 2.3382 - mse: 11.8009 \n",
      "Epoch 107/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.7005 - mae: 2.4742 - mse: 13.0209 \n",
      "Epoch 108/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9185 - mae: 2.4109 - mse: 11.0112 \n",
      "Epoch 109/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.4571 - mae: 2.3742 - mse: 10.6487 \n",
      "Epoch 110/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 13.3226 - mae: 2.5097 - mse: 13.5428\n",
      "Epoch 111/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7049 - mae: 2.3922 - mse: 10.9294\n",
      "Epoch 112/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.1749 - mae: 2.3245 - mse: 12.2456 \n",
      "Epoch 113/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5543 - mae: 2.4155 - mse: 11.7984 \n",
      "Epoch 114/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1429 - mae: 2.1522 - mse: 9.2899 \n",
      "Epoch 115/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3053 - mae: 2.2279 - mse: 9.2543 \n",
      "Epoch 116/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4018 - mae: 2.2690 - mse: 9.4178 \n",
      "Epoch 117/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8508 - mae: 2.3203 - mse: 9.8455 \n",
      "Epoch 118/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.9573 - mae: 2.5106 - mse: 13.1831\n",
      "Epoch 119/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6788 - mae: 2.2423 - mse: 9.8466 \n",
      "Epoch 120/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1323 - mae: 2.2817 - mse: 10.3351\n",
      "Epoch 121/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1913 - mae: 2.1654 - mse: 9.3039 \n",
      "Epoch 122/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3555 - mae: 2.2249 - mse: 9.2706 \n",
      "Epoch 123/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.2963 - mae: 2.3098 - mse: 10.4784 \n",
      "Epoch 124/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.0900 - mae: 2.3179 - mse: 11.2650\n",
      "Epoch 125/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0931 - mae: 2.2259 - mse: 8.6280 \n",
      "Epoch 126/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.3202 - mae: 2.4042 - mse: 12.5955 \n",
      "Epoch 127/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4960 - mae: 2.3688 - mse: 10.5980 \n",
      "Epoch 128/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6157 - mae: 2.2792 - mse: 9.0300\n",
      "Epoch 129/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4060 - mae: 2.1480 - mse: 9.3168 \n",
      "Epoch 130/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4225 - mae: 2.0795 - mse: 8.5214 \n",
      "Epoch 131/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8586 - mae: 2.2678 - mse: 10.8080\n",
      "Epoch 132/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6372 - mae: 2.2421 - mse: 9.5700 \n",
      "Epoch 133/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4013 - mae: 2.3853 - mse: 10.7554 \n",
      "Epoch 134/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7171 - mae: 2.2970 - mse: 9.6632 \n",
      "Epoch 135/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9761 - mae: 2.2336 - mse: 10.1463\n",
      "Epoch 136/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2914 - mae: 2.2242 - mse: 9.4572 \n",
      "Epoch 137/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6617 - mae: 2.1298 - mse: 8.3006 \n",
      "Epoch 138/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.1832 - mae: 2.4785 - mse: 13.0833 \n",
      "Epoch 139/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.3180 - mae: 2.3703 - mse: 11.5594 \n",
      "Epoch 140/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4709 - mae: 2.1613 - mse: 9.6562 \n",
      "Epoch 141/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.2392 - mae: 2.3988 - mse: 12.3641 \n",
      "Epoch 142/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8778 - mae: 2.1082 - mse: 8.8307 \n",
      "Epoch 143/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1647 - mae: 2.2786 - mse: 10.1661 \n",
      "Epoch 144/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9199 - mae: 2.1430 - mse: 9.0358 \n",
      "Epoch 145/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6732 - mae: 2.1804 - mse: 9.0853 \n",
      "Epoch 146/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5945 - mae: 2.2786 - mse: 11.7881 \n",
      "Epoch 147/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0393 - mae: 2.1777 - mse: 9.2746 \n",
      "Epoch 148/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.4605 - mae: 2.1992 - mse: 8.9209 \n",
      "Epoch 149/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0039 - mae: 2.2190 - mse: 10.0629\n",
      "Epoch 150/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.3991 - mae: 2.3799 - mse: 10.6022 \n",
      "Epoch 151/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0964 - mae: 2.2157 - mse: 10.0129\n",
      "Epoch 152/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.5907 - mae: 2.1900 - mse: 8.9690 \n",
      "Epoch 153/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.2447 - mae: 2.2749 - mse: 9.7687  \n",
      "Epoch 154/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1779 - mae: 2.1806 - mse: 8.7097 \n",
      "Epoch 155/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.1074 - mae: 2.3393 - mse: 12.2787 \n",
      "Epoch 156/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7719 - mae: 2.2447 - mse: 9.9273 \n",
      "Epoch 157/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2257 - mae: 2.3444 - mse: 9.8058\n",
      "Epoch 158/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.5258 - mae: 2.3006 - mse: 10.4484\n",
      "Epoch 159/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.3292 - mae: 2.1498 - mse: 9.5580 \n",
      "Epoch 160/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6429 - mae: 2.2614 - mse: 9.7324 \n",
      "Epoch 161/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 10.2157 - mae: 2.3643 - mse: 10.5194\n",
      "Epoch 162/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8824 - mae: 2.1522 - mse: 9.0270 \n",
      "Epoch 163/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4496 - mae: 2.1494 - mse: 8.7356 \n",
      "Epoch 164/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.4193 - mae: 2.3162 - mse: 11.4645 \n",
      "Epoch 165/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.6448 - mae: 2.2795 - mse: 11.7865 \n",
      "Epoch 166/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5926 - mae: 2.3305 - mse: 11.7698 \n",
      "Epoch 167/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5279 - mae: 2.4308 - mse: 10.6661 \n",
      "Epoch 168/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2736 - mae: 2.2464 - mse: 11.3140 \n",
      "Epoch 169/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.3853 - mae: 2.4659 - mse: 12.6609 \n",
      "Epoch 170/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7226 - mae: 2.2431 - mse: 9.7898 \n",
      "Epoch 171/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1625 - mae: 2.1707 - mse: 8.5753 \n",
      "Epoch 172/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9482 - mae: 2.2378 - mse: 11.2065 \n",
      "Epoch 173/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8984 - mae: 2.1980 - mse: 10.8419 \n",
      "Epoch 174/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8322 - mae: 2.4367 - mse: 12.9668 \n",
      "Epoch 175/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2128 - mae: 2.2361 - mse: 10.2748\n",
      "Epoch 176/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5667 - mae: 2.0636 - mse: 8.5096 \n",
      "Epoch 177/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9854 - mae: 2.2379 - mse: 10.1460\n",
      "Epoch 178/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4672 - mae: 2.0188 - mse: 7.9556 \n",
      "Epoch 179/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9383 - mae: 2.1665 - mse: 9.0998 \n",
      "Epoch 180/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6837 - mae: 1.9963 - mse: 7.8123 \n",
      "Epoch 181/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 12.4433 - mae: 2.4166 - mse: 12.7401 \n",
      "Epoch 182/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.5495 - mae: 2.0789 - mse: 8.6175 \n",
      "Epoch 183/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 12.1037 - mae: 2.3178 - mse: 12.0322 \n",
      "Epoch 184/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.8505 - mae: 2.4685 - mse: 13.1435 \n",
      "Epoch 185/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7176 - mae: 2.1164 - mse: 8.7995\n",
      "Epoch 186/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.7500 - mae: 2.2855 - mse: 10.0187  \n",
      "Epoch 187/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4668 - mae: 2.0898 - mse: 8.5342 \n",
      "Epoch 188/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.8578 - mae: 2.1415 - mse: 9.0355 \n",
      "Epoch 189/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.1839 - mae: 2.0920 - mse: 9.2370 \n",
      "Epoch 190/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9833 - mae: 2.2510 - mse: 10.1122\n",
      "Epoch 191/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.7537 - mae: 2.3707 - mse: 11.8639 \n",
      "Epoch 192/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2552 - mae: 2.1899 - mse: 9.5066 \n",
      "Epoch 193/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2712 - mae: 2.2704 - mse: 11.4289 \n",
      "Epoch 194/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2103 - mae: 2.2314 - mse: 11.2842 \n",
      "Epoch 195/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2113 - mae: 2.0183 - mse: 7.9930 \n",
      "Epoch 196/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6393 - mae: 2.1614 - mse: 9.6663 \n",
      "Epoch 197/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9935 - mae: 2.1626 - mse: 9.0855 \n",
      "Epoch 198/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.2206 - mae: 2.0765 - mse: 8.2840\n",
      "Epoch 199/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8361 - mae: 2.2963 - mse: 10.1173\n",
      "Epoch 200/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1417 - mae: 2.1951 - mse: 8.4001 \n",
      "Epoch 201/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6246 - mae: 2.2242 - mse: 10.8763 \n",
      "Epoch 202/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3385 - mae: 2.1079 - mse: 9.1573 \n",
      "Epoch 203/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0696 - mae: 2.1358 - mse: 9.1747 \n",
      "Epoch 204/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4155 - mae: 2.2168 - mse: 9.6801 \n",
      "Epoch 205/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.1841 - mae: 2.2377 - mse: 11.4368 \n",
      "Epoch 206/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7051 - mae: 2.1483 - mse: 8.9076 \n",
      "Epoch 207/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8375 - mae: 2.3401 - mse: 11.7730 \n",
      "Epoch 208/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9339 - mae: 2.2160 - mse: 9.5109   \n",
      "Epoch 209/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.0949 - mae: 2.3519 - mse: 12.1053 \n",
      "Epoch 210/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2671 - mae: 2.2228 - mse: 9.4337 \n",
      "Epoch 211/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2747 - mae: 1.8854 - mse: 7.2091 \n",
      "Epoch 212/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.9712 - mae: 2.1596 - mse: 10.7792 \n",
      "Epoch 213/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8162 - mae: 2.1989 - mse: 9.1084 \n",
      "Epoch 214/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6216 - mae: 2.1346 - mse: 10.7924 \n",
      "Epoch 215/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4591 - mae: 2.0401 - mse: 7.9131 \n",
      "Epoch 216/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5445 - mae: 2.2927 - mse: 11.7821 \n",
      "Epoch 217/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.7203 - mae: 2.3698 - mse: 12.0379 \n",
      "Epoch 218/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6482 - mae: 2.0339 - mse: 8.0030 \n",
      "Epoch 219/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3390 - mae: 2.2566 - mse: 11.4453 \n",
      "Epoch 220/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8914 - mae: 2.1029 - mse: 8.9693 \n",
      "Epoch 221/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5337 - mae: 2.0583 - mse: 8.4152 \n",
      "Epoch 222/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9381 - mae: 2.2679 - mse: 9.4763   \n",
      "Epoch 223/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8029 - mae: 2.1747 - mse: 10.8300 \n",
      "Epoch 224/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0316 - mae: 2.2290 - mse: 10.1062\n",
      "Epoch 225/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0597 - mae: 2.1846 - mse: 11.1536 \n",
      "Epoch 226/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.4619 - mae: 2.1466 - mse: 8.6696 \n",
      "Epoch 227/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6837 - mae: 2.1508 - mse: 9.8660 \n",
      "Epoch 228/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.7122 - mae: 2.1879 - mse: 10.6795 \n",
      "Epoch 229/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6744 - mae: 2.1556 - mse: 10.7982 \n",
      "Epoch 230/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6558 - mae: 2.0846 - mse: 8.8418 \n",
      "Epoch 231/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5218 - mae: 2.2950 - mse: 11.6132 \n",
      "Epoch 232/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9001 - mae: 2.1736 - mse: 10.8849 \n",
      "Epoch 233/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4079 - mae: 2.1876 - mse: 9.5797 \n",
      "Epoch 234/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6406 - mae: 2.0473 - mse: 8.0406 \n",
      "Epoch 235/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2308 - mae: 2.0307 - mse: 8.2758 \n",
      "Epoch 236/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4272 - mae: 2.1960 - mse: 9.6197 \n",
      "Epoch 237/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6937 - mae: 1.9145 - mse: 6.9196 \n",
      "Epoch 238/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2494 - mae: 2.1397 - mse: 9.3527 \n",
      "Epoch 239/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1890 - mae: 2.0384 - mse: 8.4036 \n",
      "Epoch 240/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4819 - mae: 2.0548 - mse: 10.3832 \n",
      "Epoch 241/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4559 - mae: 2.1395 - mse: 9.4309 \n",
      "Epoch 242/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0455 - mae: 1.9730 - mse: 7.4512 \n",
      "Epoch 243/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7511 - mae: 2.1306 - mse: 8.9249 \n",
      "Epoch 244/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9746 - mae: 2.0710 - mse: 8.4131 \n",
      "Epoch 245/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5074 - mae: 1.9237 - mse: 7.5132 \n",
      "Epoch 246/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8131 - mae: 2.0934 - mse: 9.0502 \n",
      "Epoch 247/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.0698 - mae: 2.1595 - mse: 9.3123 \n",
      "Epoch 248/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6079 - mae: 2.1192 - mse: 8.8788 \n",
      "Epoch 249/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3867 - mae: 2.1220 - mse: 9.3422 \n",
      "Epoch 250/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.3579 - mae: 2.0365 - mse: 8.3798 \n",
      "Epoch 251/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4157 - mae: 2.0150 - mse: 7.8287 \n",
      "Epoch 252/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5303 - mae: 2.1111 - mse: 8.7210 \n",
      "Epoch 253/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5067 - mae: 2.0150 - mse: 7.9365 \n",
      "Epoch 254/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0797 - mae: 2.1630 - mse: 9.2625 \n",
      "Epoch 255/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8475 - mae: 2.1708 - mse: 10.8117 \n",
      "Epoch 256/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2478 - mae: 2.0175 - mse: 8.3502 \n",
      "Epoch 257/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5754 - mae: 2.0604 - mse: 8.1340 \n",
      "Epoch 258/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1633 - mae: 2.1023 - mse: 9.2915 \n",
      "Epoch 259/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3385 - mae: 2.1133 - mse: 8.4766 \n",
      "Epoch 260/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5902 - mae: 2.0236 - mse: 8.7381 \n",
      "Epoch 261/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2089 - mae: 1.8635 - mse: 7.1347 \n",
      "Epoch 262/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8005 - mae: 2.2104 - mse: 10.9056 \n",
      "Epoch 263/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7259 - mae: 2.1591 - mse: 8.8231 \n",
      "Epoch 264/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0127 - mae: 2.0302 - mse: 8.1591 \n",
      "Epoch 265/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4408 - mae: 2.0299 - mse: 7.9033 \n",
      "Epoch 266/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9996 - mae: 2.1472 - mse: 9.2001 \n",
      "Epoch 267/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3892 - mae: 2.1273 - mse: 10.5035 \n",
      "Epoch 268/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6581 - mae: 2.1307 - mse: 8.9473 \n",
      "Epoch 269/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2666 - mae: 2.0885 - mse: 8.3276 \n",
      "Epoch 270/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5740 - mae: 2.0549 - mse: 8.6730 \n",
      "Epoch 271/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.2983 - mae: 2.1931 - mse: 11.3803 \n",
      "Epoch 272/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0374 - mae: 2.1121 - mse: 9.1993 \n",
      "Epoch 273/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0948 - mae: 2.0692 - mse: 8.2951 \n",
      "Epoch 274/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1932 - mae: 2.1287 - mse: 9.4131 \n",
      "Epoch 275/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0739 - mae: 1.9865 - mse: 8.0817 \n",
      "Epoch 276/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8328 - mae: 2.0955 - mse: 8.3550 \n",
      "Epoch 277/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5021 - mae: 2.1050 - mse: 10.4084 \n",
      "Epoch 278/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4914 - mae: 1.9071 - mse: 7.5777 \n",
      "Epoch 279/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7732 - mae: 2.0437 - mse: 8.1284 \n",
      "Epoch 280/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2025 - mae: 2.0417 - mse: 10.3013 \n",
      "Epoch 281/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6462 - mae: 1.8903 - mse: 6.7277 \n",
      "Epoch 282/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5500 - mae: 2.1441 - mse: 10.7116 \n",
      "Epoch 283/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2598 - mae: 2.0040 - mse: 7.6548 \n",
      "Epoch 284/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7289 - mae: 1.9814 - mse: 7.6730 \n",
      "Epoch 285/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8538 - mae: 2.0016 - mse: 8.1021 \n",
      "Epoch 286/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0402 - mae: 2.0399 - mse: 8.2960 \n",
      "Epoch 287/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6558 - mae: 1.9566 - mse: 7.8191 \n",
      "Epoch 288/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3071 - mae: 1.9795 - mse: 8.3971 \n",
      "Epoch 289/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9788 - mae: 2.0923 - mse: 8.3314 \n",
      "Epoch 290/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8818 - mae: 2.2435 - mse: 11.0177 \n",
      "Epoch 291/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1132 - mae: 1.9646 - mse: 7.6137 \n",
      "Epoch 292/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2566 - mae: 2.1314 - mse: 9.5300 \n",
      "Epoch 293/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8623 - mae: 1.8370 - mse: 6.9542 \n",
      "Epoch 294/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9458 - mae: 1.9574 - mse: 7.3060 \n",
      "Epoch 295/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9046 - mae: 2.0826 - mse: 9.0837 \n",
      "Epoch 296/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3055 - mae: 1.9766 - mse: 9.4480   \n",
      "Epoch 297/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.5553 - mae: 2.2937 - mse: 11.7601 \n",
      "Epoch 298/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6141 - mae: 1.9607 - mse: 7.6980 \n",
      "Epoch 299/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5005 - mae: 1.9914 - mse: 8.6926 \n",
      "Epoch 300/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.3392 - mae: 1.9095 - mse: 8.1724 \n",
      "Epoch 301/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4998 - mae: 1.9482 - mse: 8.2895 \n",
      "Epoch 302/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.4267 - mae: 1.9251 - mse: 7.6214 \n",
      "Epoch 303/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8432 - mae: 1.8960 - mse: 7.2182 \n",
      "Epoch 304/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.6855 - mae: 2.0351 - mse: 9.8175   \n",
      "Epoch 305/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6580 - mae: 2.0571 - mse: 8.5955 \n",
      "Epoch 306/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2405 - mae: 2.3036 - mse: 10.5635 \n",
      "Epoch 307/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7587 - mae: 2.0179 - mse: 8.7525 \n",
      "Epoch 308/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9482 - mae: 1.9825 - mse: 8.1893 \n",
      "Epoch 309/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9456 - mae: 1.9675 - mse: 7.9390 \n",
      "Epoch 310/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.4399 - mae: 2.1324 - mse: 10.6960 \n",
      "Epoch 311/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3226 - mae: 1.8417 - mse: 6.8117 \n",
      "Epoch 312/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9917 - mae: 2.0850 - mse: 10.2245  \n",
      "Epoch 313/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.2368 - mae: 1.9728 - mse: 8.3762 \n",
      "Epoch 314/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0468 - mae: 1.9554 - mse: 7.5369 \n",
      "Epoch 315/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8916 - mae: 2.2268 - mse: 11.1323 \n",
      "Epoch 316/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8679 - mae: 1.8087 - mse: 6.9016 \n",
      "Epoch 317/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2755 - mae: 2.0501 - mse: 8.4223 \n",
      "Epoch 318/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0596 - mae: 1.9947 - mse: 8.1099 \n",
      "Epoch 319/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2535 - mae: 2.1056 - mse: 10.3483 \n",
      "Epoch 320/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0777 - mae: 2.0015 - mse: 7.6079 \n",
      "Epoch 321/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.4229 - mae: 2.1379 - mse: 10.4765 \n",
      "Epoch 322/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2877 - mae: 2.2881 - mse: 10.5990 \n",
      "Epoch 323/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5660 - mae: 1.9248 - mse: 6.9689 \n",
      "Epoch 324/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8753 - mae: 2.0487 - mse: 9.0830 \n",
      "Epoch 325/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 11.1467 - mae: 2.2142 - mse: 11.3360\n",
      "Epoch 326/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1265 - mae: 2.1056 - mse: 9.3179 \n",
      "Epoch 327/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.0209 - mae: 1.9963 - mse: 7.4544 \n",
      "Epoch 328/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9418 - mae: 1.9551 - mse: 7.4431 \n",
      "Epoch 329/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1441 - mae: 1.9737 - mse: 7.6430 \n",
      "Epoch 330/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4906 - mae: 1.9942 - mse: 7.7001 \n",
      "Epoch 331/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9290 - mae: 1.9654 - mse: 7.3918 \n",
      "Epoch 332/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.4016 - mae: 1.8374 - mse: 6.7076 \n",
      "Epoch 333/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7940 - mae: 1.9259 - mse: 7.8680 \n",
      "Epoch 334/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8773 - mae: 2.0485 - mse: 8.9773 \n",
      "Epoch 335/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.5070 - mae: 1.9760 - mse: 8.6295 \n",
      "Epoch 336/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4139 - mae: 1.9775 - mse: 8.5236 \n",
      "Epoch 337/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0652 - mae: 2.2511 - mse: 11.2630 \n",
      "Epoch 338/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8768 - mae: 1.9491 - mse: 7.9845 \n",
      "Epoch 339/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3709 - mae: 1.9208 - mse: 6.8617 \n",
      "Epoch 340/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4437 - mae: 1.9273 - mse: 7.4749 \n",
      "Epoch 341/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2997 - mae: 1.9581 - mse: 8.5284 \n",
      "Epoch 342/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9016 - mae: 2.0769 - mse: 9.1591 \n",
      "Epoch 343/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5820 - mae: 1.9560 - mse: 7.5695 \n",
      "Epoch 344/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2973 - mae: 1.9599 - mse: 8.4869 \n",
      "Epoch 345/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3266 - mae: 2.0976 - mse: 8.5842 \n",
      "Epoch 346/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5611 - mae: 1.8747 - mse: 7.4260 \n",
      "Epoch 347/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1498 - mae: 2.0778 - mse: 9.2507 \n",
      "Epoch 348/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6405 - mae: 2.0108 - mse: 9.8060   \n",
      "Epoch 349/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6681 - mae: 1.9111 - mse: 7.1416 \n",
      "Epoch 350/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1106 - mae: 1.9646 - mse: 8.2401 \n",
      "Epoch 351/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9664 - mae: 1.9681 - mse: 8.0252 \n",
      "Epoch 352/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1843 - mae: 1.9324 - mse: 8.1886 \n",
      "Epoch 353/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9695 - mae: 1.9317 - mse: 8.1387 \n",
      "Epoch 354/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8005 - mae: 2.0540 - mse: 10.0350  \n",
      "Epoch 355/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8306 - mae: 2.1880 - mse: 11.0410 \n",
      "Epoch 356/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2294 - mae: 1.9664 - mse: 8.3444 \n",
      "Epoch 357/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.8936 - mae: 1.8869 - mse: 7.0391 \n",
      "Epoch 358/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.0411 - mae: 2.0069 - mse: 8.0740 \n",
      "Epoch 359/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4122 - mae: 1.8530 - mse: 7.5674 \n",
      "Epoch 360/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3607 - mae: 1.9961 - mse: 9.5328   \n",
      "Epoch 361/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6905 - mae: 1.9376 - mse: 7.7897 \n",
      "Epoch 362/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4374 - mae: 1.8547 - mse: 7.4495 \n",
      "Epoch 363/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1972 - mae: 1.9801 - mse: 8.3593 \n",
      "Epoch 364/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8318 - mae: 2.1191 - mse: 9.9204   \n",
      "Epoch 365/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9217 - mae: 1.9450 - mse: 7.8743 \n",
      "Epoch 366/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9001 - mae: 1.8973 - mse: 7.9731 \n",
      "Epoch 367/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5198 - mae: 1.9950 - mse: 8.7172 \n",
      "Epoch 368/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0640 - mae: 2.0573 - mse: 8.1526 \n",
      "Epoch 369/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3641 - mae: 1.9276 - mse: 9.4845   \n",
      "Epoch 370/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4857 - mae: 1.9778 - mse: 9.4315   \n",
      "Epoch 371/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3399 - mae: 1.9779 - mse: 8.3277 \n",
      "Epoch 372/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2308 - mae: 2.0773 - mse: 10.2690 \n",
      "Epoch 373/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2711 - mae: 1.8738 - mse: 7.2466 \n",
      "Epoch 374/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2643 - mae: 1.8651 - mse: 7.4686 \n",
      "Epoch 375/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.6607 - mae: 1.8852 - mse: 7.7050 \n",
      "Epoch 376/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9238 - mae: 1.7972 - mse: 7.0008 \n",
      "Epoch 377/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3238 - mae: 2.0213 - mse: 8.5166 \n",
      "Epoch 378/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1704 - mae: 1.8330 - mse: 7.3308 \n",
      "Epoch 379/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9572 - mae: 2.0516 - mse: 9.9618   \n",
      "Epoch 380/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4202 - mae: 1.8643 - mse: 6.8686 \n",
      "Epoch 381/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6231 - mae: 1.8831 - mse: 7.0910 \n",
      "Epoch 382/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4290 - mae: 2.0346 - mse: 8.6455 \n",
      "Epoch 383/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1242 - mae: 2.1004 - mse: 9.3394 \n",
      "Epoch 384/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1127 - mae: 1.9225 - mse: 8.1837 \n",
      "Epoch 385/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5580 - mae: 2.0093 - mse: 8.6940 \n",
      "Epoch 386/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4857 - mae: 1.9554 - mse: 7.5944 \n",
      "Epoch 387/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6474 - mae: 2.0052 - mse: 9.7792   \n",
      "Epoch 388/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4394 - mae: 1.8658 - mse: 6.8993 \n",
      "Epoch 389/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0469 - mae: 2.0147 - mse: 8.1699 \n",
      "Epoch 390/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.3230 - mae: 2.0061 - mse: 8.4127 \n",
      "Epoch 391/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.8277 - mae: 1.9800 - mse: 7.3947 \n",
      "Epoch 392/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.1328 - mae: 1.8228 - mse: 6.4914 \n",
      "Epoch 393/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5077 - mae: 2.0060 - mse: 9.4782   \n",
      "Epoch 394/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5493 - mae: 2.0133 - mse: 9.7105   \n",
      "Epoch 395/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9699 - mae: 1.9811 - mse: 8.1238 \n",
      "Epoch 396/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5710 - mae: 2.0141 - mse: 9.6796  \n",
      "Epoch 397/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.0405 - mae: 2.0308 - mse: 10.1826 \n",
      "Epoch 398/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3905 - mae: 1.8518 - mse: 7.4865 \n",
      "Epoch 399/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3900 - mae: 1.8713 - mse: 7.4839 \n",
      "Epoch 400/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6189 - mae: 1.8646 - mse: 7.6165 \n",
      "Epoch 401/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2031 - mae: 1.8465 - mse: 6.5613 \n",
      "Epoch 402/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4162 - mae: 1.8871 - mse: 7.5375 \n",
      "Epoch 403/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5824 - mae: 1.8869 - mse: 7.7390 \n",
      "Epoch 404/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8232 - mae: 1.9245 - mse: 7.8220 \n",
      "Epoch 405/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5858 - mae: 1.7750 - mse: 6.5387 \n",
      "Epoch 406/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3778 - mae: 1.9909 - mse: 9.6353   \n",
      "Epoch 407/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.7577 - mae: 1.8687 - mse: 8.8625   \n",
      "Epoch 408/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1765 - mae: 2.1126 - mse: 10.3977 \n",
      "Epoch 409/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.4071 - mae: 2.0030 - mse: 9.5436   \n",
      "Epoch 410/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3390 - mae: 1.9676 - mse: 9.2223   \n",
      "Epoch 411/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5439 - mae: 2.0168 - mse: 9.6885   \n",
      "Epoch 412/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8438 - mae: 1.8157 - mse: 6.7876 \n",
      "Epoch 413/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1030 - mae: 1.9226 - mse: 9.2843   \n",
      "Epoch 414/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5450 - mae: 2.0152 - mse: 9.7400   \n",
      "Epoch 415/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8249 - mae: 1.8506 - mse: 7.9293 \n",
      "Epoch 416/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.0475 - mae: 2.1233 - mse: 10.2466\n",
      "Epoch 417/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.9945 - mae: 1.9384 - mse: 8.9276   \n",
      "Epoch 418/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6154 - mae: 1.8951 - mse: 7.1764 \n",
      "Epoch 419/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5285 - mae: 1.8925 - mse: 7.1162 \n",
      "Epoch 420/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6675 - mae: 1.9283 - mse: 7.2544 \n",
      "Epoch 421/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2018 - mae: 1.8856 - mse: 9.2509   \n",
      "Epoch 422/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3667 - mae: 1.9945 - mse: 9.5561   \n",
      "Epoch 423/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3168 - mae: 1.7165 - mse: 6.3397 \n",
      "Epoch 424/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0912 - mae: 1.9468 - mse: 9.2805   \n",
      "Epoch 425/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8058 - mae: 2.0622 - mse: 10.0029  \n",
      "Epoch 426/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2781 - mae: 1.8231 - mse: 7.3095\n",
      "Epoch 427/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 7.6886 - mae: 1.9075 - mse: 7.8732 \n",
      "Epoch 428/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1072 - mae: 1.9619 - mse: 9.3066   \n",
      "Epoch 429/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5597 - mae: 1.7236 - mse: 5.8058 \n",
      "Epoch 430/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4788 - mae: 1.9931 - mse: 8.7567 \n",
      "Epoch 431/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3024 - mae: 1.8288 - mse: 7.5041 \n",
      "Epoch 432/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6816 - mae: 1.8259 - mse: 8.6981   \n",
      "Epoch 433/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2804 - mae: 1.9314 - mse: 9.4917   \n",
      "Epoch 434/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7511 - mae: 1.9103 - mse: 7.7964 \n",
      "Epoch 435/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1646 - mae: 1.8207 - mse: 6.4770 \n",
      "Epoch 436/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9561 - mae: 1.8557 - mse: 7.0491 \n",
      "Epoch 437/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1034 - mae: 1.9436 - mse: 8.9260   \n",
      "Epoch 438/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8626 - mae: 1.8763 - mse: 8.0049 \n",
      "Epoch 439/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1094 - mae: 1.8197 - mse: 6.5567 \n",
      "Epoch 440/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2893 - mae: 1.8433 - mse: 7.4939 \n",
      "Epoch 441/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7221 - mae: 1.9166 - mse: 7.8523 \n",
      "Epoch 442/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5413 - mae: 1.7840 - mse: 6.6491 \n",
      "Epoch 443/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3924 - mae: 1.7206 - mse: 5.8070 \n",
      "Epoch 444/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5591 - mae: 2.0086 - mse: 9.6407   \n",
      "Epoch 445/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5454 - mae: 1.8564 - mse: 7.5929 \n",
      "Epoch 446/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3629 - mae: 1.7563 - mse: 6.5021 \n",
      "Epoch 447/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8511 - mae: 1.9119 - mse: 8.9880   \n",
      "Epoch 448/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5656 - mae: 1.8927 - mse: 7.6785 \n",
      "Epoch 449/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6057 - mae: 1.9813 - mse: 9.6834   \n",
      "Epoch 450/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8480 - mae: 1.8660 - mse: 7.0065 \n",
      "Epoch 451/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7376 - mae: 1.9206 - mse: 7.9159 \n",
      "Epoch 452/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5154 - mae: 1.9750 - mse: 9.6462   \n",
      "Epoch 453/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9865 - mae: 1.8308 - mse: 7.2419 \n",
      "Epoch 454/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5178 - mae: 1.9070 - mse: 8.7604   \n",
      "Epoch 455/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1196 - mae: 1.8433 - mse: 6.5888 \n",
      "Epoch 456/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.6322 - mae: 1.9218 - mse: 7.1828 \n",
      "Epoch 457/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6380 - mae: 1.8012 - mse: 6.7878 \n",
      "Epoch 458/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9118 - mae: 1.7879 - mse: 7.1252 \n",
      "Epoch 459/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.3159 - mae: 1.7625 - mse: 6.3906 \n",
      "Epoch 460/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4893 - mae: 1.7546 - mse: 6.4673 \n",
      "Epoch 461/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7313 - mae: 1.7613 - mse: 6.7125 \n",
      "Epoch 462/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3945 - mae: 1.9620 - mse: 8.4989 \n",
      "Epoch 463/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4938 - mae: 1.7666 - mse: 6.0385 \n",
      "Epoch 464/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.6301 - mae: 1.8776 - mse: 8.7856   \n",
      "Epoch 465/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3405 - mae: 1.9888 - mse: 9.4708   \n",
      "Epoch 466/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1734 - mae: 1.6676 - mse: 6.1661 \n",
      "Epoch 467/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7102 - mae: 1.8951 - mse: 8.8621   \n",
      "Epoch 468/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8905 - mae: 1.8302 - mse: 7.0425 \n",
      "Epoch 469/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2717 - mae: 1.8063 - mse: 6.7852 \n",
      "Epoch 470/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5541 - mae: 1.8826 - mse: 8.6558   \n",
      "Epoch 471/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9306 - mae: 1.8237 - mse: 7.1044 \n",
      "Epoch 472/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4998 - mae: 1.8477 - mse: 7.5450 \n",
      "Epoch 473/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7274 - mae: 1.8217 - mse: 6.8691 \n",
      "Epoch 474/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6542 - mae: 1.7245 - mse: 6.1886 \n",
      "Epoch 475/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7325 - mae: 1.9064 - mse: 7.8140 \n",
      "Epoch 476/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0266 - mae: 1.9174 - mse: 9.0859   \n",
      "Epoch 477/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2929 - mae: 1.8747 - mse: 6.8692 \n",
      "Epoch 478/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4601 - mae: 1.9162 - mse: 7.6427 \n",
      "Epoch 479/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4020 - mae: 1.8339 - mse: 7.5693 \n",
      "Epoch 480/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4492 - mae: 1.8652 - mse: 7.6546 \n",
      "Epoch 481/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9921 - mae: 1.6302 - mse: 6.0184 \n",
      "Epoch 482/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7547 - mae: 1.8846 - mse: 7.8346 \n",
      "Epoch 483/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2381 - mae: 1.6485 - mse: 5.5988 \n",
      "Epoch 484/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5643 - mae: 1.8604 - mse: 7.7115 \n",
      "Epoch 485/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8012 - mae: 1.8715 - mse: 6.9668 \n",
      "Epoch 486/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1284 - mae: 1.7729 - mse: 7.3094 \n",
      "Epoch 487/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8276 - mae: 1.8776 - mse: 8.7859   \n",
      "Epoch 488/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7338 - mae: 1.8074 - mse: 7.8309 \n",
      "Epoch 489/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.9395 - mae: 1.9335 - mse: 8.1280 \n",
      "Epoch 490/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.5740 - mae: 1.8545 - mse: 7.7619 \n",
      "Epoch 491/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4856 - mae: 1.7807 - mse: 6.6225 \n",
      "Epoch 492/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0301 - mae: 1.8866 - mse: 9.1718   \n",
      "Epoch 493/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6059 - mae: 1.7079 - mse: 5.8666 \n",
      "Epoch 494/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1770 - mae: 1.8104 - mse: 7.3693 \n",
      "Epoch 495/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1047 - mae: 1.7252 - mse: 6.0318 \n",
      "Epoch 496/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9093 - mae: 1.8217 - mse: 6.9700 \n",
      "Epoch 497/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.3519 - mae: 1.8267 - mse: 6.9415 \n",
      "Epoch 498/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6218 - mae: 1.9076 - mse: 8.6539   \n",
      "Epoch 499/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5545 - mae: 1.6704 - mse: 6.0323 \n",
      "Epoch 500/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4323 - mae: 1.8543 - mse: 7.6135 \n",
      "Epoch 501/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6083 - mae: 1.7742 - mse: 6.1013 \n",
      "Epoch 502/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9337 - mae: 1.7698 - mse: 7.0013 \n",
      "Epoch 503/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.1407 - mae: 1.6758 - mse: 6.2379 \n",
      "Epoch 504/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.7823 - mae: 1.8325 - mse: 8.8870   \n",
      "Epoch 505/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.1467 - mae: 1.9716 - mse: 9.3363   \n",
      "Epoch 506/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1126 - mae: 1.7801 - mse: 7.0735 \n",
      "Epoch 507/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0265 - mae: 1.8752 - mse: 8.9696   \n",
      "Epoch 508/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3997 - mae: 1.6978 - mse: 5.9749 \n",
      "Epoch 509/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6933 - mae: 1.7334 - mse: 6.7195 \n",
      "Epoch 510/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0922 - mae: 1.7253 - mse: 6.2901 \n",
      "Epoch 511/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0858 - mae: 1.7782 - mse: 7.1905 \n",
      "Epoch 512/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2630 - mae: 1.7157 - mse: 6.2315 \n",
      "Epoch 513/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4865 - mae: 1.8551 - mse: 8.5621   \n",
      "Epoch 514/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5599 - mae: 1.8633 - mse: 8.7598   \n",
      "Epoch 515/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0741 - mae: 1.9493 - mse: 9.1333   \n",
      "Epoch 516/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.6624 - mae: 1.7345 - mse: 6.1255 \n",
      "Epoch 517/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8222 - mae: 1.6166 - mse: 5.1804 \n",
      "Epoch 518/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7715 - mae: 1.7359 - mse: 6.9281 \n",
      "Epoch 519/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8141 - mae: 1.7147 - mse: 6.9236 \n",
      "Epoch 520/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8497 - mae: 1.6161 - mse: 5.8989 \n",
      "Epoch 521/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.4935 - mae: 1.8383 - mse: 7.6894 \n",
      "Epoch 522/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.1961 - mae: 1.7992 - mse: 7.2704 \n",
      "Epoch 523/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4236 - mae: 1.7395 - mse: 6.3501 \n",
      "Epoch 524/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.0382 - mae: 1.7534 - mse: 7.0768 \n",
      "Epoch 525/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2143 - mae: 1.6482 - mse: 5.6539 \n",
      "Epoch 526/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2805 - mae: 1.7434 - mse: 6.3110 \n",
      "Epoch 527/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9009 - mae: 1.7151 - mse: 6.7634 \n",
      "Epoch 528/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0304 - mae: 1.6804 - mse: 6.2364 \n",
      "Epoch 529/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5300 - mae: 1.7852 - mse: 6.1546 \n",
      "Epoch 530/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0720 - mae: 1.8085 - mse: 8.0735   \n",
      "Epoch 531/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.4629 - mae: 1.7247 - mse: 5.9952 \n",
      "Epoch 532/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9821 - mae: 1.7583 - mse: 7.0381 \n",
      "Epoch 533/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7227 - mae: 1.5864 - mse: 5.2375 \n",
      "Epoch 534/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7996 - mae: 1.8991 - mse: 7.9954\n",
      "Epoch 535/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7634 - mae: 1.7414 - mse: 6.2749 \n",
      "Epoch 536/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.2110 - mae: 1.7669 - mse: 7.2796 \n",
      "Epoch 537/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.9433 - mae: 1.7264 - mse: 7.0493 \n",
      "Epoch 538/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3424 - mae: 1.6589 - mse: 6.5023 \n",
      "Epoch 539/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7458 - mae: 1.7629 - mse: 6.9346 \n",
      "Epoch 540/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.2732 - mae: 1.7552 - mse: 8.4444   \n",
      "Epoch 541/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8597 - mae: 1.6387 - mse: 5.8927 \n",
      "Epoch 542/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5718 - mae: 1.8626 - mse: 8.6203   \n",
      "Epoch 543/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.3011 - mae: 1.8079 - mse: 8.4534   \n",
      "Epoch 544/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.7947 - mae: 1.6976 - mse: 6.9060 \n",
      "Epoch 545/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.8088 - mae: 1.7346 - mse: 6.9870 \n",
      "Epoch 546/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.6561 - mae: 1.6725 - mse: 6.6309 \n",
      "Epoch 547/1000\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4939 - mae: 1.6945 - mse: 6.6266 \n",
      "Epoch 548/1000\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 3.2486 - mae: 1.4553 - mse: 3.2486"
     ]
    }
   ],
   "source": [
    "nn_model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=1e-6),\n",
    "    metrics=[\"mse\", \"mae\"],\n",
    ")\n",
    "nn_model.fit(X_train, y_train, epochs=1000, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a9223dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 1.1494 - mse: 3.2423 - mae: 1.1494\n",
      "[1.1493641138076782, 3.2422587871551514, 1.1493641138076782]\n"
     ]
    }
   ],
   "source": [
    "model_evaluation = nn_model.evaluate(X_test, y_test)\n",
    "print(model_evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b13b7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.6455199 , -0.32320224,  2.05673388, -1.91085627,  0.46097948,\n",
       "       -0.03182908, -0.23658887,  0.70209006, -0.33642493, -1.26407142,\n",
       "       -0.40745157,  7.14060782,  1.923334  ,  3.53708464, -0.05360954,\n",
       "        4.51605324, -2.33193166,  1.24163666, -0.29332674,  0.11361901,\n",
       "       -0.81547168, -1.30514682,  1.02622401, -2.16278886, -0.10234982,\n",
       "       -0.3094264 , -0.52588248,  2.16344362,  0.09150185, -1.01514744,\n",
       "        0.6114198 ,  0.56674162, -0.09862026,  0.44384843, -0.72829447,\n",
       "        1.13339798,  0.42322622, -0.62595552])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.T - nn_model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce6472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
